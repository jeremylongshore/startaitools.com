<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7b4d8d17fc1f501468cce40c3651aed1",
  "translation_date": "2025-07-16T22:39:18+00:00",
  "source_file": "05-AdvancedTopics/mcp-scaling/README.md",
  "language_code": "pl"
}
-->
# Skalowalność i Wysoka Wydajność MCP

W przypadku wdrożeń korporacyjnych implementacje MCP często muszą obsługiwać duże ilości żądań przy minimalnych opóźnieniach.

## Wprowadzenie

W tej lekcji omówimy strategie skalowania serwerów MCP, aby efektywnie radziły sobie z dużym obciążeniem. Przedstawimy skalowanie poziome i pionowe, optymalizację zasobów oraz architektury rozproszone.

## Cele nauki

Po ukończeniu tej lekcji będziesz potrafił:

- Wdrażać skalowanie poziome za pomocą równoważenia obciążenia i rozproszonego cache’owania.
- Optymalizować serwery MCP pod kątem skalowania pionowego i zarządzania zasobami.
- Projektować rozproszone architektury MCP zapewniające wysoką dostępność i odporność na błędy.
- Wykorzystywać zaawansowane narzędzia i techniki do monitorowania wydajności i optymalizacji.
- Stosować najlepsze praktyki skalowania serwerów MCP w środowiskach produkcyjnych.

## Strategie skalowalności

Istnieje kilka strategii efektywnego skalowania serwerów MCP:

- **Skalowanie poziome**: Uruchomienie wielu instancji serwerów MCP za load balancerem, aby równomiernie rozdzielać przychodzące żądania.
- **Skalowanie pionowe**: Optymalizacja pojedynczej instancji serwera MCP, aby obsłużyć więcej żądań poprzez zwiększenie zasobów (CPU, pamięć) i dostosowanie konfiguracji.
- **Optymalizacja zasobów**: Wykorzystanie wydajnych algorytmów, cache’owania i przetwarzania asynchronicznego w celu zmniejszenia zużycia zasobów i skrócenia czasu odpowiedzi.
- **Architektura rozproszona**: Wdrożenie systemu rozproszonego, w którym wiele węzłów MCP współpracuje, dzieląc obciążenie i zapewniając redundancję.

## Skalowanie poziome

Skalowanie poziome polega na uruchomieniu wielu instancji serwerów MCP i wykorzystaniu load balancera do rozdzielania przychodzących żądań. Takie podejście pozwala obsłużyć więcej żądań jednocześnie i zapewnia odporność na awarie.

Spójrzmy na przykład konfiguracji skalowania poziomego i MCP.

### [.NET](../../../../05-AdvancedTopics/mcp-scaling)

```csharp
// ASP.NET Core MCP load balancing configuration
public class McpLoadBalancedStartup
{
    public void ConfigureServices(IServiceCollection services)
    {
        // Configure distributed cache for session state
        services.AddStackExchangeRedisCache(options =>
        {
            options.Configuration = Configuration.GetConnectionString("RedisConnection");
            options.InstanceName = "MCP_";
        });
        
        // Configure MCP with distributed caching
        services.AddMcpServer(options =>
        {
            options.ServerName = "Scalable MCP Server";
            options.ServerVersion = "1.0.0";
            options.EnableDistributedCaching = true;
            options.CacheExpirationMinutes = 60;
        });
        
        // Register tools
        services.AddMcpTool<HighPerformanceTool>();
    }
}
```

W powyższym kodzie:

- Skonfigurowaliśmy rozproszony cache za pomocą Redis do przechowywania stanu sesji i danych narzędzi.
- Włączyliśmy rozproszone cache’owanie w konfiguracji serwera MCP.
- Zarejestrowaliśmy narzędzie o wysokiej wydajności, które może być używane na wielu instancjach MCP.

---

## Skalowanie pionowe i optymalizacja zasobów

Skalowanie pionowe koncentruje się na optymalizacji pojedynczej instancji serwera MCP, aby efektywnie obsłużyć więcej żądań. Można to osiągnąć poprzez dostosowanie konfiguracji, stosowanie wydajnych algorytmów oraz efektywne zarządzanie zasobami. Na przykład można regulować pule wątków, limity czasu żądań i ograniczenia pamięci, aby poprawić wydajność.

Spójrzmy na przykład optymalizacji serwera MCP pod kątem skalowania pionowego i zarządzania zasobami.

# [Java](../../../../05-AdvancedTopics/mcp-scaling)

```java
// Java MCP server with resource optimization
public class OptimizedMcpServer {
    public static McpServer createOptimizedServer() {
        // Configure thread pool for optimal performance
        int processors = Runtime.getRuntime().availableProcessors();
        int optimalThreads = processors * 2; // Common heuristic for I/O-bound tasks
        
        ExecutorService executorService = new ThreadPoolExecutor(
            processors,       // Core pool size
            optimalThreads,   // Maximum pool size 
            60L,              // Keep-alive time
            TimeUnit.SECONDS,
            new ArrayBlockingQueue<>(1000), // Request queue size
            new ThreadPoolExecutor.CallerRunsPolicy() // Backpressure strategy
        );
        
        // Configure and build MCP server with resource constraints
        return new McpServer.Builder()
            .setName("High-Performance MCP Server")
            .setVersion("1.0.0")
            .setPort(5000)
            .setExecutor(executorService)
            .setMaxRequestSize(1024 * 1024) // 1MB
            .setMaxConcurrentRequests(100)
            .setRequestTimeoutMs(5000) // 5 seconds
            .build();
    }
}
```

W powyższym kodzie:

- Skonfigurowaliśmy pulę wątków z optymalną liczbą wątków, bazującą na liczbie dostępnych procesorów.
- Ustawiliśmy ograniczenia zasobów, takie jak maksymalny rozmiar żądania, maksymalna liczba jednoczesnych żądań oraz limit czasu żądania.
- Zastosowaliśmy strategię backpressure, aby łagodnie radzić sobie z przeciążeniem.

---

## Architektura rozproszona

Architektury rozproszone obejmują wiele węzłów MCP współpracujących ze sobą w celu obsługi żądań, dzielenia zasobów i zapewnienia redundancji. Takie podejście zwiększa skalowalność i odporność na błędy, umożliwiając węzłom komunikację i koordynację w ramach systemu rozproszonego.

Spójrzmy na przykład implementacji rozproszonej architektury serwera MCP z wykorzystaniem Redis do koordynacji.

# [Python](../../../../05-AdvancedTopics/mcp-scaling)

```python
# Python MCP server in distributed architecture
from mcp_server import AsyncMcpServer
import asyncio
import aioredis
import uuid

class DistributedMcpServer:
    def __init__(self, node_id=None):
        self.node_id = node_id or str(uuid.uuid4())
        self.redis = None
        self.server = None
    
    async def initialize(self):
        # Connect to Redis for coordination
        self.redis = await aioredis.create_redis_pool("redis://redis-master:6379")
        
        # Register this node with the cluster
        await self.redis.sadd("mcp:nodes", self.node_id)
        await self.redis.hset(f"mcp:node:{self.node_id}", "status", "starting")
        
        # Create the MCP server
        self.server = AsyncMcpServer(
            name=f"MCP Node {self.node_id[:8]}",
            version="1.0.0",
            port=5000,
            max_concurrent_requests=50
        )
        
        # Register tools - each node might specialize in certain tools
        self.register_tools()
        
        # Start heartbeat mechanism
        asyncio.create_task(self._heartbeat())
        
        # Start server
        await self.server.start()
        
        # Update node status
        await self.redis.hset(f"mcp:node:{self.node_id}", "status", "running")
        print(f"MCP Node {self.node_id[:8]} running on port 5000")
    
    def register_tools(self):
        # Register common tools across all nodes
        self.server.register_tool(CommonTool1())
        self.server.register_tool(CommonTool2())
        
        # Register specialized tools for this node (could be based on node_id or config)
        if int(self.node_id[-1], 16) % 3 == 0:  # Simple way to distribute specialized tools
            self.server.register_tool(SpecializedTool1())
        elif int(self.node_id[-1], 16) % 3 == 1:
            self.server.register_tool(SpecializedTool2())
        else:
            self.server.register_tool(SpecializedTool3())
    
    async def _heartbeat(self):
        """Periodic heartbeat to indicate node health"""
        while True:
            try:
                await self.redis.hset(
                    f"mcp:node:{self.node_id}", 
                    mapping={
                        "lastHeartbeat": int(time.time()),
                        "load": len(self.server.active_requests),
                        "maxLoad": self.server.max_concurrent_requests
                    }
                )
                await asyncio.sleep(5)  # Heartbeat every 5 seconds
            except Exception as e:
                print(f"Heartbeat error: {e}")
                await asyncio.sleep(1)
    
    async def shutdown(self):
        await self.redis.hset(f"mcp:node:{self.node_id}", "status", "stopping")
        await self.server.stop()
        await self.redis.srem("mcp:nodes", self.node_id)
        await self.redis.delete(f"mcp:node:{self.node_id}")
        self.redis.close()
        await self.redis.wait_closed()
```

W powyższym kodzie:

- Utworzono rozproszony serwer MCP, który rejestruje się w instancji Redis w celu koordynacji.
- Zaimplementowano mechanizm heartbeat do aktualizacji statusu i obciążenia węzła w Redis.
- Zarejestrowano narzędzia, które mogą być specjalizowane w zależności od ID węzła, co pozwala na rozkładanie obciążenia między węzłami.
- Udostępniono metodę zamknięcia do zwalniania zasobów i wyrejestrowania węzła z klastra.
- Wykorzystano programowanie asynchroniczne do efektywnej obsługi żądań i utrzymania responsywności.
- Użyto Redis do koordynacji i zarządzania stanem w rozproszonych węzłach.

---

## Co dalej

- [5.8 Security](../mcp-security/README.md)

**Zastrzeżenie**:  
Niniejszy dokument został przetłumaczony za pomocą usługi tłumaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mimo że dążymy do jak największej dokładności, prosimy mieć na uwadze, że tłumaczenia automatyczne mogą zawierać błędy lub nieścisłości. Oryginalny dokument w języku źródłowym powinien być uznawany za źródło autorytatywne. W przypadku informacji o kluczowym znaczeniu zalecane jest skorzystanie z profesjonalnego tłumaczenia wykonanego przez człowieka. Nie ponosimy odpowiedzialności za jakiekolwiek nieporozumienia lub błędne interpretacje wynikające z korzystania z tego tłumaczenia.