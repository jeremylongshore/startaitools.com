<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7b4d8d17fc1f501468cce40c3651aed1",
  "translation_date": "2025-07-17T07:55:02+00:00",
  "source_file": "05-AdvancedTopics/mcp-scaling/README.md",
  "language_code": "id"
}
-->
# Skalabilitas dan MCP Berkinerja Tinggi

Untuk penerapan di perusahaan, implementasi MCP sering kali harus menangani volume permintaan yang tinggi dengan latensi minimal.

## Pendahuluan

Dalam pelajaran ini, kita akan membahas strategi untuk menskalakan server MCP agar dapat menangani beban kerja besar secara efisien. Kita akan membahas skalabilitas horizontal dan vertikal, optimasi sumber daya, serta arsitektur terdistribusi.

## Tujuan Pembelajaran

Pada akhir pelajaran ini, Anda akan mampu:

- Menerapkan skalabilitas horizontal menggunakan load balancing dan caching terdistribusi.
- Mengoptimalkan server MCP untuk skalabilitas vertikal dan manajemen sumber daya.
- Merancang arsitektur MCP terdistribusi untuk ketersediaan tinggi dan toleransi kesalahan.
- Memanfaatkan alat dan teknik lanjutan untuk pemantauan dan optimasi kinerja.
- Menerapkan praktik terbaik untuk menskalakan server MCP di lingkungan produksi.

## Strategi Skalabilitas

Ada beberapa strategi untuk menskalakan server MCP secara efektif:

- **Skalabilitas Horizontal**: Menyebarkan beberapa instance server MCP di belakang load balancer untuk mendistribusikan permintaan yang masuk secara merata.
- **Skalabilitas Vertikal**: Mengoptimalkan satu instance server MCP agar dapat menangani lebih banyak permintaan dengan menambah sumber daya (CPU, memori) dan menyetel konfigurasi secara tepat.
- **Optimasi Sumber Daya**: Menggunakan algoritma yang efisien, caching, dan pemrosesan asinkron untuk mengurangi konsumsi sumber daya dan mempercepat waktu respons.
- **Arsitektur Terdistribusi**: Menerapkan sistem terdistribusi di mana beberapa node MCP bekerja sama, berbagi beban, dan menyediakan redundansi.

## Skalabilitas Horizontal

Skalabilitas horizontal melibatkan penyebaran beberapa instance server MCP dan menggunakan load balancer untuk mendistribusikan permintaan yang masuk. Pendekatan ini memungkinkan Anda menangani lebih banyak permintaan secara bersamaan dan menyediakan toleransi kesalahan.

Mari kita lihat contoh cara mengonfigurasi skalabilitas horizontal dan MCP.

### [.NET](../../../../05-AdvancedTopics/mcp-scaling)

```csharp
// ASP.NET Core MCP load balancing configuration
public class McpLoadBalancedStartup
{
    public void ConfigureServices(IServiceCollection services)
    {
        // Configure distributed cache for session state
        services.AddStackExchangeRedisCache(options =>
        {
            options.Configuration = Configuration.GetConnectionString("RedisConnection");
            options.InstanceName = "MCP_";
        });
        
        // Configure MCP with distributed caching
        services.AddMcpServer(options =>
        {
            options.ServerName = "Scalable MCP Server";
            options.ServerVersion = "1.0.0";
            options.EnableDistributedCaching = true;
            options.CacheExpirationMinutes = 60;
        });
        
        // Register tools
        services.AddMcpTool<HighPerformanceTool>();
    }
}
```

Dalam kode sebelumnya kami telah:

- Mengonfigurasi cache terdistribusi menggunakan Redis untuk menyimpan status sesi dan data alat.
- Mengaktifkan caching terdistribusi dalam konfigurasi server MCP.
- Mendaftarkan alat berkinerja tinggi yang dapat digunakan di beberapa instance MCP.

---

## Skalabilitas Vertikal dan Optimasi Sumber Daya

Skalabilitas vertikal berfokus pada mengoptimalkan satu instance server MCP agar dapat menangani lebih banyak permintaan secara efisien. Ini dapat dicapai dengan menyetel konfigurasi secara tepat, menggunakan algoritma yang efisien, dan mengelola sumber daya dengan baik. Misalnya, Anda dapat menyesuaikan thread pool, batas waktu permintaan, dan batas memori untuk meningkatkan kinerja.

Mari kita lihat contoh cara mengoptimalkan server MCP untuk skalabilitas vertikal dan manajemen sumber daya.

# [Java](../../../../05-AdvancedTopics/mcp-scaling)

```java
// Java MCP server with resource optimization
public class OptimizedMcpServer {
    public static McpServer createOptimizedServer() {
        // Configure thread pool for optimal performance
        int processors = Runtime.getRuntime().availableProcessors();
        int optimalThreads = processors * 2; // Common heuristic for I/O-bound tasks
        
        ExecutorService executorService = new ThreadPoolExecutor(
            processors,       // Core pool size
            optimalThreads,   // Maximum pool size 
            60L,              // Keep-alive time
            TimeUnit.SECONDS,
            new ArrayBlockingQueue<>(1000), // Request queue size
            new ThreadPoolExecutor.CallerRunsPolicy() // Backpressure strategy
        );
        
        // Configure and build MCP server with resource constraints
        return new McpServer.Builder()
            .setName("High-Performance MCP Server")
            .setVersion("1.0.0")
            .setPort(5000)
            .setExecutor(executorService)
            .setMaxRequestSize(1024 * 1024) // 1MB
            .setMaxConcurrentRequests(100)
            .setRequestTimeoutMs(5000) // 5 seconds
            .build();
    }
}
```

Dalam kode sebelumnya, kami telah:

- Mengonfigurasi thread pool dengan jumlah thread optimal berdasarkan jumlah prosesor yang tersedia.
- Menetapkan batas sumber daya seperti ukuran permintaan maksimum, jumlah permintaan bersamaan maksimum, dan batas waktu permintaan.
- Menggunakan strategi backpressure untuk menangani situasi kelebihan beban dengan baik.

---

## Arsitektur Terdistribusi

Arsitektur terdistribusi melibatkan beberapa node MCP yang bekerja sama untuk menangani permintaan, berbagi sumber daya, dan menyediakan redundansi. Pendekatan ini meningkatkan skalabilitas dan toleransi kesalahan dengan memungkinkan node berkomunikasi dan berkoordinasi melalui sistem terdistribusi.

Mari kita lihat contoh cara mengimplementasikan arsitektur server MCP terdistribusi menggunakan Redis untuk koordinasi.

# [Python](../../../../05-AdvancedTopics/mcp-scaling)

```python
# Python MCP server in distributed architecture
from mcp_server import AsyncMcpServer
import asyncio
import aioredis
import uuid

class DistributedMcpServer:
    def __init__(self, node_id=None):
        self.node_id = node_id or str(uuid.uuid4())
        self.redis = None
        self.server = None
    
    async def initialize(self):
        # Connect to Redis for coordination
        self.redis = await aioredis.create_redis_pool("redis://redis-master:6379")
        
        # Register this node with the cluster
        await self.redis.sadd("mcp:nodes", self.node_id)
        await self.redis.hset(f"mcp:node:{self.node_id}", "status", "starting")
        
        # Create the MCP server
        self.server = AsyncMcpServer(
            name=f"MCP Node {self.node_id[:8]}",
            version="1.0.0",
            port=5000,
            max_concurrent_requests=50
        )
        
        # Register tools - each node might specialize in certain tools
        self.register_tools()
        
        # Start heartbeat mechanism
        asyncio.create_task(self._heartbeat())
        
        # Start server
        await self.server.start()
        
        # Update node status
        await self.redis.hset(f"mcp:node:{self.node_id}", "status", "running")
        print(f"MCP Node {self.node_id[:8]} running on port 5000")
    
    def register_tools(self):
        # Register common tools across all nodes
        self.server.register_tool(CommonTool1())
        self.server.register_tool(CommonTool2())
        
        # Register specialized tools for this node (could be based on node_id or config)
        if int(self.node_id[-1], 16) % 3 == 0:  # Simple way to distribute specialized tools
            self.server.register_tool(SpecializedTool1())
        elif int(self.node_id[-1], 16) % 3 == 1:
            self.server.register_tool(SpecializedTool2())
        else:
            self.server.register_tool(SpecializedTool3())
    
    async def _heartbeat(self):
        """Periodic heartbeat to indicate node health"""
        while True:
            try:
                await self.redis.hset(
                    f"mcp:node:{self.node_id}", 
                    mapping={
                        "lastHeartbeat": int(time.time()),
                        "load": len(self.server.active_requests),
                        "maxLoad": self.server.max_concurrent_requests
                    }
                )
                await asyncio.sleep(5)  # Heartbeat every 5 seconds
            except Exception as e:
                print(f"Heartbeat error: {e}")
                await asyncio.sleep(1)
    
    async def shutdown(self):
        await self.redis.hset(f"mcp:node:{self.node_id}", "status", "stopping")
        await self.server.stop()
        await self.redis.srem("mcp:nodes", self.node_id)
        await self.redis.delete(f"mcp:node:{self.node_id}")
        self.redis.close()
        await self.redis.wait_closed()
```

Dalam kode sebelumnya, kami telah:

- Membuat server MCP terdistribusi yang mendaftarkan dirinya ke instance Redis untuk koordinasi.
- Menerapkan mekanisme heartbeat untuk memperbarui status dan beban node di Redis.
- Mendaftarkan alat yang dapat disesuaikan berdasarkan ID node, memungkinkan distribusi beban antar node.
- Menyediakan metode shutdown untuk membersihkan sumber daya dan membatalkan pendaftaran node dari klaster.
- Menggunakan pemrograman asinkron untuk menangani permintaan secara efisien dan menjaga responsivitas.
- Memanfaatkan Redis untuk koordinasi dan manajemen status antar node terdistribusi.

---

## Selanjutnya

- [5.8 Security](../mcp-security/README.md)

**Penafian**:  
Dokumen ini telah diterjemahkan menggunakan layanan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Meskipun kami berupaya untuk mencapai akurasi, harap diketahui bahwa terjemahan otomatis mungkin mengandung kesalahan atau ketidakakuratan. Dokumen asli dalam bahasa aslinya harus dianggap sebagai sumber yang sahih. Untuk informasi penting, disarankan menggunakan terjemahan profesional oleh manusia. Kami tidak bertanggung jawab atas kesalahpahaman atau penafsiran yang keliru yang timbul dari penggunaan terjemahan ini.