<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7b4d8d17fc1f501468cce40c3651aed1",
  "translation_date": "2025-07-17T12:24:00+00:00",
  "source_file": "05-AdvancedTopics/mcp-scaling/README.md",
  "language_code": "sl"
}
-->
# Razširljivost in visoka zmogljivost MCP

Za podjetniške namestitve morajo implementacije MCP pogosto obvladovati velike količine zahtev z minimalno zakasnitvijo.

## Uvod

V tej lekciji bomo raziskali strategije za razširjanje MCP strežnikov, da učinkovito obvladujejo velike obremenitve. Pokrili bomo horizontalno in vertikalno skaliranje, optimizacijo virov ter distribuirane arhitekture.

## Cilji učenja

Ob koncu te lekcije boste znali:

- Izvesti horizontalno skaliranje z uporabo uravnoteženja obremenitve in distribuiranega predpomnjenja.
- Optimizirati MCP strežnike za vertikalno skaliranje in upravljanje virov.
- Načrtovati distribuirane MCP arhitekture za visoko razpoložljivost in odpornost na napake.
- Uporabiti napredna orodja in tehnike za spremljanje zmogljivosti in optimizacijo.
- Uvesti najboljše prakse za skaliranje MCP strežnikov v produkcijskih okoljih.

## Strategije skaliranja

Obstaja več strategij za učinkovito skaliranje MCP strežnikov:

- **Horizontalno skaliranje**: Namestitev več instanc MCP strežnikov za uravnoteženje dohodnih zahtev preko load balancerja.
- **Vertikalno skaliranje**: Optimizacija ene instance MCP strežnika za obdelavo več zahtev z večanjem virov (CPU, pomnilnik) in prilagajanjem nastavitev.
- **Optimizacija virov**: Uporaba učinkovitih algoritmov, predpomnjenja in asinhrone obdelave za zmanjšanje porabe virov in izboljšanje odzivnosti.
- **Distribuirana arhitektura**: Implementacija distribuiranega sistema, kjer več MCP vozlišč sodeluje, deli obremenitev in zagotavlja redundanco.

## Horizontalno skaliranje

Horizontalno skaliranje vključuje namestitev več instanc MCP strežnikov in uporabo load balancerja za enakomerno razporeditev dohodnih zahtev. Ta pristop omogoča hkratno obdelavo več zahtev in zagotavlja odpornost na napake.

Poglejmo primer, kako konfigurirati horizontalno skaliranje in MCP.

### [.NET](../../../../05-AdvancedTopics/mcp-scaling)

```csharp
// ASP.NET Core MCP load balancing configuration
public class McpLoadBalancedStartup
{
    public void ConfigureServices(IServiceCollection services)
    {
        // Configure distributed cache for session state
        services.AddStackExchangeRedisCache(options =>
        {
            options.Configuration = Configuration.GetConnectionString("RedisConnection");
            options.InstanceName = "MCP_";
        });
        
        // Configure MCP with distributed caching
        services.AddMcpServer(options =>
        {
            options.ServerName = "Scalable MCP Server";
            options.ServerVersion = "1.0.0";
            options.EnableDistributedCaching = true;
            options.CacheExpirationMinutes = 60;
        });
        
        // Register tools
        services.AddMcpTool<HighPerformanceTool>();
    }
}
```

V zgornji kodi smo:

- Konfigurirali distribuirani predpomnilnik z uporabo Redis za shranjevanje stanja sej in podatkov orodij.
- Omogočili distribuirano predpomnjenje v konfiguraciji MCP strežnika.
- Registrirali visoko zmogljivo orodje, ki ga je mogoče uporabljati na več MCP instancah.

---

## Vertikalno skaliranje in optimizacija virov

Vertikalno skaliranje se osredotoča na optimizacijo ene instance MCP strežnika za učinkovitejšo obdelavo več zahtev. To dosežemo z natančnim prilagajanjem nastavitev, uporabo učinkovitih algoritmov in učinkovitim upravljanjem virov. Na primer, lahko prilagodite thread poole, časovne omejitve zahtev in omejitve pomnilnika za izboljšanje zmogljivosti.

Poglejmo primer, kako optimizirati MCP strežnik za vertikalno skaliranje in upravljanje virov.

# [Java](../../../../05-AdvancedTopics/mcp-scaling)

```java
// Java MCP server with resource optimization
public class OptimizedMcpServer {
    public static McpServer createOptimizedServer() {
        // Configure thread pool for optimal performance
        int processors = Runtime.getRuntime().availableProcessors();
        int optimalThreads = processors * 2; // Common heuristic for I/O-bound tasks
        
        ExecutorService executorService = new ThreadPoolExecutor(
            processors,       // Core pool size
            optimalThreads,   // Maximum pool size 
            60L,              // Keep-alive time
            TimeUnit.SECONDS,
            new ArrayBlockingQueue<>(1000), // Request queue size
            new ThreadPoolExecutor.CallerRunsPolicy() // Backpressure strategy
        );
        
        // Configure and build MCP server with resource constraints
        return new McpServer.Builder()
            .setName("High-Performance MCP Server")
            .setVersion("1.0.0")
            .setPort(5000)
            .setExecutor(executorService)
            .setMaxRequestSize(1024 * 1024) // 1MB
            .setMaxConcurrentRequests(100)
            .setRequestTimeoutMs(5000) // 5 seconds
            .build();
    }
}
```

V zgornji kodi smo:

- Konfigurirali thread pool z optimalnim številom niti glede na število razpoložljivih procesorjev.
- Nastavili omejitve virov, kot so največja velikost zahteve, največje število sočasnih zahtev in časovna omejitev zahteve.
- Uporabili strategijo backpressure za elegantno obvladovanje preobremenjenosti.

---

## Distribuirana arhitektura

Distribuirane arhitekture vključujejo več MCP vozlišč, ki sodelujejo pri obdelavi zahtev, delitvi virov in zagotavljanju redundance. Ta pristop izboljšuje skalabilnost in odpornost na napake, saj vozlišča komunicirajo in se usklajujejo preko distribuiranega sistema.

Poglejmo primer, kako implementirati distribuirano MCP strežniško arhitekturo z uporabo Redis za koordinacijo.

# [Python](../../../../05-AdvancedTopics/mcp-scaling)

```python
# Python MCP server in distributed architecture
from mcp_server import AsyncMcpServer
import asyncio
import aioredis
import uuid

class DistributedMcpServer:
    def __init__(self, node_id=None):
        self.node_id = node_id or str(uuid.uuid4())
        self.redis = None
        self.server = None
    
    async def initialize(self):
        # Connect to Redis for coordination
        self.redis = await aioredis.create_redis_pool("redis://redis-master:6379")
        
        # Register this node with the cluster
        await self.redis.sadd("mcp:nodes", self.node_id)
        await self.redis.hset(f"mcp:node:{self.node_id}", "status", "starting")
        
        # Create the MCP server
        self.server = AsyncMcpServer(
            name=f"MCP Node {self.node_id[:8]}",
            version="1.0.0",
            port=5000,
            max_concurrent_requests=50
        )
        
        # Register tools - each node might specialize in certain tools
        self.register_tools()
        
        # Start heartbeat mechanism
        asyncio.create_task(self._heartbeat())
        
        # Start server
        await self.server.start()
        
        # Update node status
        await self.redis.hset(f"mcp:node:{self.node_id}", "status", "running")
        print(f"MCP Node {self.node_id[:8]} running on port 5000")
    
    def register_tools(self):
        # Register common tools across all nodes
        self.server.register_tool(CommonTool1())
        self.server.register_tool(CommonTool2())
        
        # Register specialized tools for this node (could be based on node_id or config)
        if int(self.node_id[-1], 16) % 3 == 0:  # Simple way to distribute specialized tools
            self.server.register_tool(SpecializedTool1())
        elif int(self.node_id[-1], 16) % 3 == 1:
            self.server.register_tool(SpecializedTool2())
        else:
            self.server.register_tool(SpecializedTool3())
    
    async def _heartbeat(self):
        """Periodic heartbeat to indicate node health"""
        while True:
            try:
                await self.redis.hset(
                    f"mcp:node:{self.node_id}", 
                    mapping={
                        "lastHeartbeat": int(time.time()),
                        "load": len(self.server.active_requests),
                        "maxLoad": self.server.max_concurrent_requests
                    }
                )
                await asyncio.sleep(5)  # Heartbeat every 5 seconds
            except Exception as e:
                print(f"Heartbeat error: {e}")
                await asyncio.sleep(1)
    
    async def shutdown(self):
        await self.redis.hset(f"mcp:node:{self.node_id}", "status", "stopping")
        await self.server.stop()
        await self.redis.srem("mcp:nodes", self.node_id)
        await self.redis.delete(f"mcp:node:{self.node_id}")
        self.redis.close()
        await self.redis.wait_closed()
```

V zgornji kodi smo:

- Ustvarili distribuirani MCP strežnik, ki se registrira pri Redis instanci za koordinacijo.
- Implementirali mehanizem heartbeat za posodabljanje statusa in obremenitve vozlišča v Redis.
- Registrirali orodja, ki se lahko specializirajo glede na ID vozlišča, kar omogoča razporeditev obremenitve med vozlišči.
- Zagotovili metodo za zaustavitev, ki počisti vire in odjavi vozlišče iz gruče.
- Uporabili asinhrono programiranje za učinkovito obdelavo zahtev in ohranjanje odzivnosti.
- Izkoristili Redis za koordinacijo in upravljanje stanja med distribuiranimi vozlišči.

---

## Kaj sledi

- [5.8 Security](../mcp-security/README.md)

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo AI prevajalske storitve [Co-op Translator](https://github.com/Azure/co-op-translator). Čeprav si prizadevamo za natančnost, vas opozarjamo, da avtomatizirani prevodi lahko vsebujejo napake ali netočnosti. Izvirni dokument v njegovem izvirnem jeziku velja za avtoritativni vir. Za ključne informacije priporočamo strokovni človeški prevod. Za morebitna nesporazume ali napačne interpretacije, ki izhajajo iz uporabe tega prevoda, ne odgovarjamo.