<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7b4d8d17fc1f501468cce40c3651aed1",
  "translation_date": "2025-07-16T20:56:54+00:00",
  "source_file": "05-AdvancedTopics/mcp-scaling/README.md",
  "language_code": "zh"
}
-->
# 可扩展性与高性能 MCP

对于企业级部署，MCP 实现通常需要处理大量请求并保持极低的延迟。

## 介绍

本课将探讨扩展 MCP 服务器以高效处理大规模工作负载的策略。内容涵盖水平扩展与垂直扩展、资源优化以及分布式架构。

## 学习目标

完成本课后，您将能够：

- 使用负载均衡和分布式缓存实现水平扩展。
- 优化 MCP 服务器以支持垂直扩展和资源管理。
- 设计具备高可用性和容错能力的分布式 MCP 架构。
- 利用先进工具和技术进行性能监控与优化。
- 应用生产环境中 MCP 服务器扩展的最佳实践。

## 扩展策略

有效扩展 MCP 服务器的策略包括：

- **水平扩展**：在负载均衡器后部署多个 MCP 服务器实例，均匀分配请求。
- **垂直扩展**：通过增加资源（CPU、内存）和调整配置，优化单个 MCP 服务器实例以处理更多请求。
- **资源优化**：采用高效算法、缓存和异步处理，降低资源消耗并提升响应速度。
- **分布式架构**：构建多个 MCP 节点协同工作，分担负载并提供冗余保障。

## 水平扩展

水平扩展指部署多个 MCP 服务器实例，并通过负载均衡器分配请求。此方法可同时处理更多请求，并增强容错能力。

下面是配置水平扩展和 MCP 的示例。

### [.NET](../../../../05-AdvancedTopics/mcp-scaling)

```csharp
// ASP.NET Core MCP load balancing configuration
public class McpLoadBalancedStartup
{
    public void ConfigureServices(IServiceCollection services)
    {
        // Configure distributed cache for session state
        services.AddStackExchangeRedisCache(options =>
        {
            options.Configuration = Configuration.GetConnectionString("RedisConnection");
            options.InstanceName = "MCP_";
        });
        
        // Configure MCP with distributed caching
        services.AddMcpServer(options =>
        {
            options.ServerName = "Scalable MCP Server";
            options.ServerVersion = "1.0.0";
            options.EnableDistributedCaching = true;
            options.CacheExpirationMinutes = 60;
        });
        
        // Register tools
        services.AddMcpTool<HighPerformanceTool>();
    }
}
```

上述代码中，我们：

- 使用 Redis 配置了分布式缓存，用于存储会话状态和工具数据。
- 在 MCP 服务器配置中启用了分布式缓存。
- 注册了可跨多个 MCP 实例使用的高性能工具。

---

## 垂直扩展与资源优化

垂直扩展侧重于优化单个 MCP 服务器实例以更高效地处理请求。可通过调整配置、采用高效算法和有效管理资源实现。例如，调整线程池、请求超时和内存限制以提升性能。

下面是优化 MCP 服务器以支持垂直扩展和资源管理的示例。

# [Java](../../../../05-AdvancedTopics/mcp-scaling)

```java
// Java MCP server with resource optimization
public class OptimizedMcpServer {
    public static McpServer createOptimizedServer() {
        // Configure thread pool for optimal performance
        int processors = Runtime.getRuntime().availableProcessors();
        int optimalThreads = processors * 2; // Common heuristic for I/O-bound tasks
        
        ExecutorService executorService = new ThreadPoolExecutor(
            processors,       // Core pool size
            optimalThreads,   // Maximum pool size 
            60L,              // Keep-alive time
            TimeUnit.SECONDS,
            new ArrayBlockingQueue<>(1000), // Request queue size
            new ThreadPoolExecutor.CallerRunsPolicy() // Backpressure strategy
        );
        
        // Configure and build MCP server with resource constraints
        return new McpServer.Builder()
            .setName("High-Performance MCP Server")
            .setVersion("1.0.0")
            .setPort(5000)
            .setExecutor(executorService)
            .setMaxRequestSize(1024 * 1024) // 1MB
            .setMaxConcurrentRequests(100)
            .setRequestTimeoutMs(5000) // 5 seconds
            .build();
    }
}
```

上述代码中，我们：

- 根据可用处理器数量配置了线程池的最优线程数。
- 设置了资源限制，如最大请求大小、最大并发请求数和请求超时。
- 使用背压策略优雅地处理过载情况。

---

## 分布式架构

分布式架构由多个 MCP 节点协同工作，处理请求、共享资源并提供冗余。该方法通过节点间的通信与协调，提升扩展性和容错能力。

下面是使用 Redis 进行协调，实现分布式 MCP 服务器架构的示例。

# [Python](../../../../05-AdvancedTopics/mcp-scaling)

```python
# Python MCP server in distributed architecture
from mcp_server import AsyncMcpServer
import asyncio
import aioredis
import uuid

class DistributedMcpServer:
    def __init__(self, node_id=None):
        self.node_id = node_id or str(uuid.uuid4())
        self.redis = None
        self.server = None
    
    async def initialize(self):
        # Connect to Redis for coordination
        self.redis = await aioredis.create_redis_pool("redis://redis-master:6379")
        
        # Register this node with the cluster
        await self.redis.sadd("mcp:nodes", self.node_id)
        await self.redis.hset(f"mcp:node:{self.node_id}", "status", "starting")
        
        # Create the MCP server
        self.server = AsyncMcpServer(
            name=f"MCP Node {self.node_id[:8]}",
            version="1.0.0",
            port=5000,
            max_concurrent_requests=50
        )
        
        # Register tools - each node might specialize in certain tools
        self.register_tools()
        
        # Start heartbeat mechanism
        asyncio.create_task(self._heartbeat())
        
        # Start server
        await self.server.start()
        
        # Update node status
        await self.redis.hset(f"mcp:node:{self.node_id}", "status", "running")
        print(f"MCP Node {self.node_id[:8]} running on port 5000")
    
    def register_tools(self):
        # Register common tools across all nodes
        self.server.register_tool(CommonTool1())
        self.server.register_tool(CommonTool2())
        
        # Register specialized tools for this node (could be based on node_id or config)
        if int(self.node_id[-1], 16) % 3 == 0:  # Simple way to distribute specialized tools
            self.server.register_tool(SpecializedTool1())
        elif int(self.node_id[-1], 16) % 3 == 1:
            self.server.register_tool(SpecializedTool2())
        else:
            self.server.register_tool(SpecializedTool3())
    
    async def _heartbeat(self):
        """Periodic heartbeat to indicate node health"""
        while True:
            try:
                await self.redis.hset(
                    f"mcp:node:{self.node_id}", 
                    mapping={
                        "lastHeartbeat": int(time.time()),
                        "load": len(self.server.active_requests),
                        "maxLoad": self.server.max_concurrent_requests
                    }
                )
                await asyncio.sleep(5)  # Heartbeat every 5 seconds
            except Exception as e:
                print(f"Heartbeat error: {e}")
                await asyncio.sleep(1)
    
    async def shutdown(self):
        await self.redis.hset(f"mcp:node:{self.node_id}", "status", "stopping")
        await self.server.stop()
        await self.redis.srem("mcp:nodes", self.node_id)
        await self.redis.delete(f"mcp:node:{self.node_id}")
        self.redis.close()
        await self.redis.wait_closed()
```

上述代码中，我们：

- 创建了一个分布式 MCP 服务器，注册到 Redis 实例以实现协调。
- 实现了心跳机制，定期更新节点在 Redis 中的状态和负载。
- 注册了可根据节点 ID 专门化的工具，实现节点间负载分配。
- 提供了关闭方法，用于清理资源并从集群注销节点。
- 采用异步编程高效处理请求，保持响应性。
- 利用 Redis 实现分布式节点间的协调和状态管理。

---

## 后续内容

- [5.8 安全](../mcp-security/README.md)

**免责声明**：  
本文件使用 AI 翻译服务 [Co-op Translator](https://github.com/Azure/co-op-translator) 进行翻译。虽然我们力求准确，但请注意，自动翻译可能包含错误或不准确之处。原始语言的文档应被视为权威来源。对于重要信息，建议使用专业人工翻译。我们不对因使用本翻译而产生的任何误解或误释承担责任。