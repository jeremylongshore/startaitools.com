<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7b4d8d17fc1f501468cce40c3651aed1",
  "translation_date": "2025-07-17T06:43:07+00:00",
  "source_file": "05-AdvancedTopics/mcp-scaling/README.md",
  "language_code": "no"
}
-->
# Skalerbarhet og høyytelses MCP

For bedriftsdistribusjoner må MCP-implementasjoner ofte håndtere store mengder forespørsler med minimal ventetid.

## Introduksjon

I denne leksjonen skal vi utforske strategier for å skalere MCP-servere slik at de kan håndtere store arbeidsmengder effektivt. Vi vil dekke horisontal og vertikal skalering, ressursoptimalisering og distribuerte arkitekturer.

## Læringsmål

Etter denne leksjonen vil du kunne:

- Implementere horisontal skalering ved bruk av lastbalansering og distribuert caching.
- Optimalisere MCP-servere for vertikal skalering og ressursstyring.
- Designe distribuerte MCP-arkitekturer for høy tilgjengelighet og feiltoleranse.
- Bruke avanserte verktøy og teknikker for ytelsesovervåking og optimalisering.
- Anvende beste praksis for skalering av MCP-servere i produksjonsmiljøer.

## Skaleringsstrategier

Det finnes flere strategier for å skalere MCP-servere effektivt:

- **Horisontal skalering**: Distribuer flere MCP-serverinstanser bak en lastbalanserer for å fordele innkommende forespørsler jevnt.
- **Vertikal skalering**: Optimaliser en enkelt MCP-serverinstans for å håndtere flere forespørsler ved å øke ressurser (CPU, minne) og finjustere konfigurasjoner.
- **Ressursoptimalisering**: Bruk effektive algoritmer, caching og asynkron behandling for å redusere ressursbruk og forbedre responstider.
- **Distribuert arkitektur**: Implementer et distribuert system der flere MCP-noder samarbeider, deler belastningen og gir redundans.

## Horisontal skalering

Horisontal skalering innebærer å distribuere flere MCP-serverinstanser og bruke en lastbalanserer for å fordele innkommende forespørsler. Denne tilnærmingen gjør det mulig å håndtere flere forespørsler samtidig og gir feiltoleranse.

La oss se på et eksempel på hvordan man konfigurerer horisontal skalering og MCP.

### [.NET](../../../../05-AdvancedTopics/mcp-scaling)

```csharp
// ASP.NET Core MCP load balancing configuration
public class McpLoadBalancedStartup
{
    public void ConfigureServices(IServiceCollection services)
    {
        // Configure distributed cache for session state
        services.AddStackExchangeRedisCache(options =>
        {
            options.Configuration = Configuration.GetConnectionString("RedisConnection");
            options.InstanceName = "MCP_";
        });
        
        // Configure MCP with distributed caching
        services.AddMcpServer(options =>
        {
            options.ServerName = "Scalable MCP Server";
            options.ServerVersion = "1.0.0";
            options.EnableDistributedCaching = true;
            options.CacheExpirationMinutes = 60;
        });
        
        // Register tools
        services.AddMcpTool<HighPerformanceTool>();
    }
}
```

I koden ovenfor har vi:

- Konfigurert en distribuert cache ved hjelp av Redis for å lagre sesjonstilstand og verktøydata.
- Aktivert distribuert caching i MCP-serverkonfigurasjonen.
- Registrert et høyytelsesverktøy som kan brukes på tvers av flere MCP-instansene.

---

## Vertikal skalering og ressursoptimalisering

Vertikal skalering fokuserer på å optimalisere en enkelt MCP-serverinstans for å håndtere flere forespørsler effektivt. Dette kan oppnås ved å finjustere konfigurasjoner, bruke effektive algoritmer og håndtere ressurser på en god måte. For eksempel kan du justere trådpuljer, tidsavbrudd for forespørsler og minnegrenser for å forbedre ytelsen.

La oss se på et eksempel på hvordan man optimaliserer en MCP-server for vertikal skalering og ressursstyring.

# [Java](../../../../05-AdvancedTopics/mcp-scaling)

```java
// Java MCP server with resource optimization
public class OptimizedMcpServer {
    public static McpServer createOptimizedServer() {
        // Configure thread pool for optimal performance
        int processors = Runtime.getRuntime().availableProcessors();
        int optimalThreads = processors * 2; // Common heuristic for I/O-bound tasks
        
        ExecutorService executorService = new ThreadPoolExecutor(
            processors,       // Core pool size
            optimalThreads,   // Maximum pool size 
            60L,              // Keep-alive time
            TimeUnit.SECONDS,
            new ArrayBlockingQueue<>(1000), // Request queue size
            new ThreadPoolExecutor.CallerRunsPolicy() // Backpressure strategy
        );
        
        // Configure and build MCP server with resource constraints
        return new McpServer.Builder()
            .setName("High-Performance MCP Server")
            .setVersion("1.0.0")
            .setPort(5000)
            .setExecutor(executorService)
            .setMaxRequestSize(1024 * 1024) // 1MB
            .setMaxConcurrentRequests(100)
            .setRequestTimeoutMs(5000) // 5 seconds
            .build();
    }
}
```

I koden ovenfor har vi:

- Konfigurert en trådpulje med et optimalt antall tråder basert på antall tilgjengelige prosessorer.
- Satt ressursbegrensninger som maksimal forespørselsstørrelse, maksimalt antall samtidige forespørsler og tidsavbrudd for forespørsler.
- Brukt en backpressure-strategi for å håndtere overbelastningssituasjoner på en kontrollert måte.

---

## Distribuert arkitektur

Distribuerte arkitekturer innebærer at flere MCP-noder samarbeider for å håndtere forespørsler, dele ressurser og gi redundans. Denne tilnærmingen øker skalerbarheten og feiltoleransen ved at nodene kan kommunisere og koordinere gjennom et distribuert system.

La oss se på et eksempel på hvordan man implementerer en distribuert MCP-serverarkitektur ved bruk av Redis for koordinering.

# [Python](../../../../05-AdvancedTopics/mcp-scaling)

```python
# Python MCP server in distributed architecture
from mcp_server import AsyncMcpServer
import asyncio
import aioredis
import uuid

class DistributedMcpServer:
    def __init__(self, node_id=None):
        self.node_id = node_id or str(uuid.uuid4())
        self.redis = None
        self.server = None
    
    async def initialize(self):
        # Connect to Redis for coordination
        self.redis = await aioredis.create_redis_pool("redis://redis-master:6379")
        
        # Register this node with the cluster
        await self.redis.sadd("mcp:nodes", self.node_id)
        await self.redis.hset(f"mcp:node:{self.node_id}", "status", "starting")
        
        # Create the MCP server
        self.server = AsyncMcpServer(
            name=f"MCP Node {self.node_id[:8]}",
            version="1.0.0",
            port=5000,
            max_concurrent_requests=50
        )
        
        # Register tools - each node might specialize in certain tools
        self.register_tools()
        
        # Start heartbeat mechanism
        asyncio.create_task(self._heartbeat())
        
        # Start server
        await self.server.start()
        
        # Update node status
        await self.redis.hset(f"mcp:node:{self.node_id}", "status", "running")
        print(f"MCP Node {self.node_id[:8]} running on port 5000")
    
    def register_tools(self):
        # Register common tools across all nodes
        self.server.register_tool(CommonTool1())
        self.server.register_tool(CommonTool2())
        
        # Register specialized tools for this node (could be based on node_id or config)
        if int(self.node_id[-1], 16) % 3 == 0:  # Simple way to distribute specialized tools
            self.server.register_tool(SpecializedTool1())
        elif int(self.node_id[-1], 16) % 3 == 1:
            self.server.register_tool(SpecializedTool2())
        else:
            self.server.register_tool(SpecializedTool3())
    
    async def _heartbeat(self):
        """Periodic heartbeat to indicate node health"""
        while True:
            try:
                await self.redis.hset(
                    f"mcp:node:{self.node_id}", 
                    mapping={
                        "lastHeartbeat": int(time.time()),
                        "load": len(self.server.active_requests),
                        "maxLoad": self.server.max_concurrent_requests
                    }
                )
                await asyncio.sleep(5)  # Heartbeat every 5 seconds
            except Exception as e:
                print(f"Heartbeat error: {e}")
                await asyncio.sleep(1)
    
    async def shutdown(self):
        await self.redis.hset(f"mcp:node:{self.node_id}", "status", "stopping")
        await self.server.stop()
        await self.redis.srem("mcp:nodes", self.node_id)
        await self.redis.delete(f"mcp:node:{self.node_id}")
        self.redis.close()
        await self.redis.wait_closed()
```

I koden ovenfor har vi:

- Opprettet en distribuert MCP-server som registrerer seg hos en Redis-instans for koordinering.
- Implementert en heartbeat-mekanisme for å oppdatere nodens status og belastning i Redis.
- Registrert verktøy som kan spesialiseres basert på nodens ID, noe som tillater belastningsfordeling mellom nodene.
- Tilbydd en avslutningsmetode for å rydde opp ressurser og avregistrere noden fra klyngen.
- Brukt asynkron programmering for å håndtere forespørsler effektivt og opprettholde responsivitet.
- Benyttet Redis for koordinering og tilstandshåndtering på tvers av distribuerte noder.

---

## Hva skjer videre

- [5.8 Security](../mcp-security/README.md)

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter nøyaktighet, vennligst vær oppmerksom på at automatiske oversettelser kan inneholde feil eller unøyaktigheter. Det opprinnelige dokumentet på originalspråket skal anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforståelser eller feiltolkninger som oppstår ved bruk av denne oversettelsen.