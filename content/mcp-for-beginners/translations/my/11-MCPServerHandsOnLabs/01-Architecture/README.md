<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "d72a1d9e9ad1a7cc8d40d05d546b5ca0",
  "translation_date": "2025-09-30T23:12:36+00:00",
  "source_file": "11-MCPServerHandsOnLabs/01-Architecture/README.md",
  "language_code": "my"
}
-->
# ·Ä°·Äì·Ä≠·ÄÄ Architecture ·Ä°·Äö·Ä∞·Ä°·ÄÜ·Äô·Äª·Ä¨·Ä∏

## üéØ ·Äí·ÄÆ Lab ·Äô·Äæ·Ä¨ ·Äò·Ä¨·Äê·ÄΩ·Ä±·ÄÄ·Ä≠·ÄØ ·Äú·Ä±·Ä∑·Äú·Ä¨·Äô·Äú·Ä≤

·Äí·ÄÆ Lab ·ÄÄ MCP server architecture patterns, database design principles, ·Äî·Ä≤·Ä∑ database-integrated AI applications ·Äê·ÄΩ·Ä±·ÄÄ·Ä≠·ÄØ ·ÄÅ·Ä≠·ÄØ·ÄÑ·Ä∫·ÄÅ·Ä∂·Ä∑·Äï·Äº·ÄÆ·Ä∏ scalable ·Äñ·Äº·ÄÖ·Ä∫·Ä°·Ä±·Ä¨·ÄÑ·Ä∫ ·Äñ·Äî·Ä∫·Äê·ÄÆ·Ä∏·Äê·Ä≤·Ä∑ ·Äî·Ää·Ä∫·Ä∏·Äú·Äô·Ä∫·Ä∏·Äê·ÄΩ·Ä±·ÄÄ·Ä≠·ÄØ ·Ä°·Äî·ÄÄ·Ä∫·Äî·ÄÄ·Ä∫·Äõ·Äæ·ÄÑ·Ä∫·Ä∏·Äú·ÄÑ·Ä∫·Ä∏·ÄÖ·ÄΩ·Ä¨ ·Äú·Ä±·Ä∑·Äú·Ä¨·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·ÄÖ·Ä±·Äô·Äæ·Ä¨ ·Äñ·Äº·ÄÖ·Ä∫·Äï·Ä´·Äê·Äö·Ä∫·Åã

## ·Ä°·ÄÄ·Äª·Äâ·Ä∫·Ä∏·ÄÅ·Äª·ÄØ·Äï·Ä∫

Database integration ·Äï·Ä´·Äù·ÄÑ·Ä∫·Äê·Ä≤·Ä∑ production-ready MCP server ·Äê·ÄÖ·Ä∫·ÄÅ·ÄØ·ÄÄ·Ä≠·ÄØ ·Äê·Ää·Ä∫·ÄÜ·Ä±·Ä¨·ÄÄ·Ä∫·Äñ·Ä≠·ÄØ·Ä∑·Ä°·Äê·ÄΩ·ÄÄ·Ä∫ architecture ·ÄÜ·Ä≠·ÄØ·ÄÑ·Ä∫·Äõ·Ä¨ ·ÄÜ·ÄØ·Ä∂·Ä∏·Äñ·Äº·Äê·Ä∫·ÄÅ·Äª·ÄÄ·Ä∫·Äê·ÄΩ·Ä±·ÄÄ·Ä≠·ÄØ ·Äû·Ä±·ÄÅ·Äª·Ä¨·ÄÖ·ÄΩ·Ä¨ ·Äú·ÄØ·Äï·Ä∫·ÄÜ·Ä±·Ä¨·ÄÑ·Ä∫·Äõ·Äï·Ä´·Äô·Äö·Ä∫·Åã ·Äí·ÄÆ Lab ·ÄÄ Zava Retail analytics solution ·ÄÄ·Ä≠·ÄØ ·ÄÅ·Ä≠·ÄØ·ÄÑ·Ä∫·ÄÅ·Ä∂·Ä∑·Äï·Äº·ÄÆ·Ä∏ secure ·Äñ·Äº·ÄÖ·Ä∫·Ä°·Ä±·Ä¨·ÄÑ·Ä∫·Åä scalable ·Äñ·Äº·ÄÖ·Ä∫·Ä°·Ä±·Ä¨·ÄÑ·Ä∫ ·Äñ·Äî·Ä∫·Äê·ÄÆ·Ä∏·Äê·Ä≤·Ä∑ ·Ä°·Äì·Ä≠·ÄÄ component ·Äê·ÄΩ·Ä±·Åä design patterns ·Äê·ÄΩ·Ä±·Åä ·Äî·Ää·Ä∫·Ä∏·Äï·Ää·Ä¨·ÄÜ·Ä≠·ÄØ·ÄÑ·Ä∫·Äõ·Ä¨ ·Ä°·ÄÅ·Äª·ÄÄ·Ä∫·Ä°·Äú·ÄÄ·Ä∫·Äê·ÄΩ·Ä±·ÄÄ·Ä≠·ÄØ ·ÄÅ·ÄΩ·Ä≤·ÄÅ·Äº·Äô·Ä∫·Ä∏·Äõ·Äæ·ÄÑ·Ä∫·Ä∏·Äú·ÄÑ·Ä∫·Ä∏·Äë·Ä¨·Ä∏·Äï·Ä´·Äê·Äö·Ä∫·Åã

·Äí·ÄÆ Lab ·Äô·Äæ·Ä¨ layer ·Äê·ÄÖ·Ä∫·ÄÅ·ÄØ·ÄÅ·Äª·ÄÑ·Ä∫·Ä∏·ÄÖ·ÄÆ ·Äò·Äö·Ä∫·Äú·Ä≠·ÄØ ·Ä°·Äú·ÄØ·Äï·Ä∫·Äú·ÄØ·Äï·Ä∫·Äû·Äú·Ä≤·Åä ·Äò·Ä¨·ÄÄ·Äº·Ä±·Ä¨·ÄÑ·Ä∑·Ä∫ ·Ä°·Äë·Ä∞·Ä∏·Äû·Äñ·Äº·ÄÑ·Ä∑·Ä∫ ·Äî·Ää·Ä∫·Ä∏·Äï·Ää·Ä¨·Äê·ÄΩ·Ä±·ÄÄ·Ä≠·ÄØ ·Äõ·ÄΩ·Ä±·Ä∏·ÄÅ·Äª·Äö·Ä∫·Äë·Ä¨·Ä∏·Äû·Äú·Ä≤·Åä MCP implementation ·ÄÄ·Ä≠·ÄØ ·ÄÄ·Ä≠·ÄØ·Äö·Ä∫·Äê·Ä≠·ÄØ·ÄÑ·Ä∫·Äú·ÄØ·Äï·Ä∫·ÄÜ·Ä±·Ä¨·ÄÑ·Ä∫·Äõ·Ä¨·Äô·Äæ·Ä¨ ·Äí·ÄÆ patterns ·Äê·ÄΩ·Ä±·ÄÄ·Ä≠·ÄØ ·Äò·Äö·Ä∫·Äú·Ä≠·ÄØ ·Ä°·Äû·ÄØ·Ä∂·Ä∏·ÄÅ·Äª·Äõ·Äô·Äú·Ä≤·ÄÜ·Ä≠·ÄØ·Äê·Ä¨·ÄÄ·Ä≠·ÄØ ·Äî·Ä¨·Ä∏·Äú·Ää·Ä∫·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Äï·Ä´·Äô·Äö·Ä∫·Åã

## ·Äú·Ä±·Ä∑·Äú·Ä¨·Äõ·Äô·Äö·Ä∑·Ä∫ ·Ä°·ÄÅ·Äª·ÄÄ·Ä∫·Äô·Äª·Ä¨·Ä∏

·Äí·ÄÆ Lab ·ÄÄ·Ä≠·ÄØ ·Äï·Äº·ÄÆ·Ä∏·ÄÜ·ÄØ·Ä∂·Ä∏·Äê·Ä≤·Ä∑·Ä°·ÄÅ·Ä´·Äô·Äæ·Ä¨ ·Äû·ÄÑ·Ä∫·Äê·ÄÖ·Ä∫·Ä¶·Ä∏·Ä¶·Ä∏·Ä°·Äî·Ä±·Äî·Ä≤·Ä∑:

- **·ÄÅ·ÄΩ·Ä≤·ÄÅ·Äº·Äô·Ä∫·Ä∏·ÄÖ·Ä≠·Äê·Ä∫·Äñ·Äº·Ä¨·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Äô·Äö·Ä∫** MCP server architecture ·ÄÄ·Ä≠·ÄØ database integration ·Äï·Ä´·Äù·ÄÑ·Ä∫·Äê·Ä≤·Ä∑ ·Ä°·ÄÅ·Äº·Ä±·ÄÅ·Ä∂ layer ·Äê·ÄΩ·Ä±·ÄÄ·Ä≠·ÄØ
- **·Äî·Ä¨·Ä∏·Äú·Ää·Ä∫·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Äô·Äö·Ä∫** architecture component ·Äê·ÄÖ·Ä∫·ÄÅ·ÄØ·ÄÅ·Äª·ÄÑ·Ä∫·Ä∏·ÄÖ·ÄÆ·Äõ·Ä≤·Ä∑ ·Ä°·ÄÅ·Äî·Ä∫·Ä∏·ÄÄ·Äè·Äπ·Äç·Äî·Ä≤·Ä∑ ·Äê·Ä¨·Äù·Äî·Ä∫
- **·Äí·ÄÆ·Äá·Ä≠·ÄØ·ÄÑ·Ä∫·Ä∏·ÄÜ·ÄΩ·Ä≤·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Äô·Äö·Ä∫** multi-tenant MCP applications ·Äê·ÄΩ·Ä±·ÄÄ·Ä≠·ÄØ ·Äï·Ä∂·Ä∑·Äï·Ä≠·ÄØ·Ä∏·Äï·Ä±·Ä∏·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Äê·Ä≤·Ä∑ database schemas
- **·Ä°·ÄÄ·Ä±·Ä¨·ÄÑ·Ä∫·Ä°·Äë·Ää·Ä∫·Äñ·Ä±·Ä¨·Ä∫·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Äô·Äö·Ä∫** connection pooling ·Äî·Ä≤·Ä∑ resource management ·Äî·Ää·Ä∫·Ä∏·Äú·Äô·Ä∫·Ä∏·Äê·ÄΩ·Ä±
- **·Ä°·Äû·ÄØ·Ä∂·Ä∏·ÄÅ·Äª·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Äô·Äö·Ä∫** production systems ·Äê·ÄΩ·Ä±·Ä°·Äê·ÄΩ·ÄÄ·Ä∫ error handling ·Äî·Ä≤·Ä∑ logging patterns
- **·Ä°·ÄÄ·Ä≤·Äñ·Äº·Äê·Ä∫·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Äô·Äö·Ä∫** architecture ·Äî·Ää·Ä∫·Ä∏·Äú·Äô·Ä∫·Ä∏·Ä°·Äô·Äª·Ä≠·ÄØ·Ä∏·Äô·Äª·Ä≠·ÄØ·Ä∏·ÄÄ·Äº·Ä¨·Ä∏·ÄÄ trade-offs

## üèóÔ∏è MCP Server Architecture Layers

MCP server ·ÄÄ **layered architecture** ·ÄÄ·Ä≠·ÄØ ·Ä°·Äû·ÄØ·Ä∂·Ä∏·Äï·Äº·ÄØ·Äë·Ä¨·Ä∏·Äï·Äº·ÄÆ·Ä∏ concern ·Äê·ÄΩ·Ä±·ÄÄ·Ä≠·ÄØ ·ÄÅ·ÄΩ·Ä≤·ÄÅ·Äº·Ä¨·Ä∏·Äë·Ä¨·Ä∏·ÄÄ·Ä¨ maintainability ·ÄÄ·Ä≠·ÄØ ·Äô·Äº·Äæ·ÄÑ·Ä∑·Ä∫·Äê·ÄÑ·Ä∫·Äï·Ä±·Ä∏·Äï·Ä´·Äê·Äö·Ä∫·Åã

### Layer 1: Protocol Layer (FastMCP)
**·Äê·Ä¨·Äù·Äî·Ä∫**: MCP protocol communication ·Äî·Ä≤·Ä∑ message routing ·ÄÄ·Ä≠·ÄØ ·ÄÄ·Ä≠·ÄØ·ÄÑ·Ä∫·Äê·ÄΩ·Äö·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏

```python
# FastMCP server setup
from fastmcp import FastMCP

mcp = FastMCP("Zava Retail Analytics")

# Tool registration with type safety
@mcp.tool()
async def execute_sales_query(
    ctx: Context,
    postgresql_query: Annotated[str, Field(description="Well-formed PostgreSQL query")]
) -> str:
    """Execute PostgreSQL queries with Row Level Security."""
    return await query_executor.execute(postgresql_query, ctx)
```

**·Ä°·Äì·Ä≠·ÄÄ ·Ä°·ÄÑ·Ä∫·Äπ·ÄÇ·Ä´·Äõ·Äï·Ä∫·Äô·Äª·Ä¨·Ä∏**:
- **Protocol Compliance**: MCP specification ·Ä°·Äï·Äº·Ää·Ä∑·Ä∫·Ä°·Äù·ÄÄ·Ä≠·ÄØ ·Äï·Ä∂·Ä∑·Äï·Ä≠·ÄØ·Ä∏·Äï·Ä±·Ä∏·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏
- **Type Safety**: request/response validation ·Ä°·Äê·ÄΩ·ÄÄ·Ä∫ Pydantic models
- **Async Support**: high concurrency ·Ä°·Äê·ÄΩ·ÄÄ·Ä∫ non-blocking I/O
- **Error Handling**: error response ·Äê·ÄΩ·Ä±·ÄÄ·Ä≠·ÄØ standardize ·Äú·ÄØ·Äï·Ä∫·Äë·Ä¨·Ä∏·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏

### Layer 2: Business Logic Layer
**·Äê·Ä¨·Äù·Äî·Ä∫**: business rules ·Äê·ÄΩ·Ä±·ÄÄ·Ä≠·ÄØ ·Ä°·ÄÄ·Ä±·Ä¨·ÄÑ·Ä∫·Ä°·Äë·Ää·Ä∫·Äñ·Ä±·Ä¨·Ä∫·Äï·Äº·ÄÆ·Ä∏ protocol ·Äî·Ä≤·Ä∑ data layer ·Äê·ÄΩ·Ä±·ÄÄ·Ä≠·ÄØ coordinate ·Äú·ÄØ·Äï·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏

```python
class SalesAnalyticsService:
    """Business logic for retail analytics operations."""
    
    async def get_store_performance(
        self, 
        store_id: str, 
        time_period: str
    ) -> Dict[str, Any]:
        """Calculate store performance metrics."""
        
        # Validate business rules
        if not self._validate_store_access(store_id):
            raise UnauthorizedError("Access denied for store")
        
        # Coordinate data retrieval
        sales_data = await self.db_provider.get_sales_data(store_id, time_period)
        metrics = self._calculate_metrics(sales_data)
        
        return {
            "store_id": store_id,
            "period": time_period,
            "metrics": metrics,
            "insights": self._generate_insights(metrics)
        }
```

**·Ä°·Äì·Ä≠·ÄÄ ·Ä°·ÄÑ·Ä∫·Äπ·ÄÇ·Ä´·Äõ·Äï·Ä∫·Äô·Äª·Ä¨·Ä∏**:
- **Business Rule Enforcement**: store access validation ·Äî·Ä≤·Ä∑ data integrity
- **Service Coordination**: database ·Äî·Ä≤·Ä∑ AI services ·Äê·ÄΩ·Ä±·ÄÄ·Äº·Ä¨·Ä∏·Äô·Äæ·Ä¨ orchestration
- **Data Transformation**: raw data ·ÄÄ·Ä≠·ÄØ business insights ·Ä°·Äñ·Äº·ÄÖ·Ä∫ ·Äï·Äº·Ä±·Ä¨·ÄÑ·Ä∫·Ä∏·Äú·Ä≤·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏
- **Caching Strategy**: frequent queries ·Ä°·Äê·ÄΩ·ÄÄ·Ä∫ performance optimization

### Layer 3: Data Access Layer
**·Äê·Ä¨·Äù·Äî·Ä∫**: database connections, query execution, ·Äî·Ä≤·Ä∑ data mapping ·ÄÄ·Ä≠·ÄØ ·ÄÄ·Ä≠·ÄØ·ÄÑ·Ä∫·Äê·ÄΩ·Äö·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏

```python
class PostgreSQLProvider:
    """Data access layer for PostgreSQL operations."""
    
    def __init__(self, connection_config: Dict[str, Any]):
        self.connection_pool: Optional[Pool] = None
        self.config = connection_config
    
    async def execute_query(
        self, 
        query: str, 
        rls_user_id: str
    ) -> List[Dict[str, Any]]:
        """Execute query with RLS context."""
        
        async with self.connection_pool.acquire() as conn:
            # Set RLS context
            await conn.execute(
                "SELECT set_config('app.current_rls_user_id', $1, false)",
                rls_user_id
            )
            
            # Execute query with timeout
            try:
                rows = await asyncio.wait_for(
                    conn.fetch(query),
                    timeout=30.0
                )
                return [dict(row) for row in rows]
            except asyncio.TimeoutError:
                raise QueryTimeoutError("Query execution exceeded timeout")
```

**·Ä°·Äì·Ä≠·ÄÄ ·Ä°·ÄÑ·Ä∫·Äπ·ÄÇ·Ä´·Äõ·Äï·Ä∫·Äô·Äª·Ä¨·Ä∏**:
- **Connection Pooling**: resource management ·ÄÄ·Ä≠·ÄØ ·Äë·Ä≠·Äõ·Ä±·Ä¨·ÄÄ·Ä∫·ÄÖ·ÄΩ·Ä¨ ·Äú·ÄØ·Äï·Ä∫·ÄÜ·Ä±·Ä¨·ÄÑ·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏
- **Transaction Management**: ACID compliance ·Äî·Ä≤·Ä∑ rollback handling
- **Query Optimization**: performance monitoring ·Äî·Ä≤·Ä∑ optimization
- **RLS Integration**: Row-level security context management

### Layer 4: Infrastructure Layer
**·Äê·Ä¨·Äù·Äî·Ä∫**: logging, monitoring, ·Äî·Ä≤·Ä∑ configuration ·ÄÖ·Äê·Ä≤·Ä∑ cross-cutting concerns ·Äê·ÄΩ·Ä±·ÄÄ·Ä≠·ÄØ ·ÄÄ·Ä≠·ÄØ·ÄÑ·Ä∫·Äê·ÄΩ·Äö·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏

```python
class InfrastructureManager:
    """Infrastructure concerns management."""
    
    def __init__(self):
        self.logger = self._setup_logging()
        self.metrics = self._setup_metrics()
        self.config = self._load_configuration()
    
    def _setup_logging(self) -> Logger:
        """Configure structured logging."""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(),
                logging.FileHandler('mcp_server.log')
            ]
        )
        return logging.getLogger(__name__)
    
    async def track_query_execution(
        self, 
        query_type: str, 
        duration: float, 
        success: bool
    ):
        """Track query performance metrics."""
        self.metrics.counter('query_total').labels(
            type=query_type,
            status='success' if success else 'error'
        ).inc()
        
        self.metrics.histogram('query_duration').labels(
            type=query_type
        ).observe(duration)
```

## üóÑÔ∏è Database Design Patterns

PostgreSQL schema ·ÄÄ multi-tenant MCP applications ·Ä°·Äê·ÄΩ·ÄÄ·Ä∫ ·Ä°·Äì·Ä≠·ÄÄ pattern ·Ä°·ÄÅ·Äª·Ä≠·ÄØ·Ä∑·ÄÄ·Ä≠·ÄØ ·Ä°·Äû·ÄØ·Ä∂·Ä∏·Äï·Äº·ÄØ·Äë·Ä¨·Ä∏·Äï·Ä´·Äê·Äö·Ä∫:

### 1. Multi-Tenant Schema Design

```sql
-- Core retail entities with store-based partitioning
CREATE TABLE retail.stores (
    store_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(100) NOT NULL,
    location VARCHAR(200) NOT NULL,
    manager_id UUID NOT NULL,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE retail.customers (
    customer_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    store_id UUID REFERENCES retail.stores(store_id),
    first_name VARCHAR(50) NOT NULL,
    last_name VARCHAR(50) NOT NULL,
    email VARCHAR(100) UNIQUE,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE retail.orders (
    order_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    customer_id UUID REFERENCES retail.customers(customer_id),
    store_id UUID REFERENCES retail.stores(store_id),
    order_date TIMESTAMP DEFAULT NOW(),
    total_amount DECIMAL(10,2) NOT NULL,
    status VARCHAR(20) DEFAULT 'pending'
);
```

**·Äí·ÄÆ·Äá·Ä≠·ÄØ·ÄÑ·Ä∫·Ä∏·Ä°·ÄÅ·Äº·Ä±·ÄÅ·Ä∂·Ä°·Äö·Ä∞·Ä°·ÄÜ·Äô·Äª·Ä¨·Ä∏**:
- **Foreign Key Consistency**: table ·Äê·ÄΩ·Ä±·ÄÄ·Äº·Ä¨·Ä∏ data integrity ·ÄÄ·Ä≠·ÄØ ·Ä°·Ä¨·Äô·ÄÅ·Ä∂·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏
- **Store ID Propagation**: transactional table ·Äê·ÄÖ·Ä∫·ÄÅ·ÄØ·ÄÅ·Äª·ÄÑ·Ä∫·Ä∏·ÄÖ·ÄÆ·Äô·Äæ·Ä¨ store_id ·Äï·Ä´·Äù·ÄÑ·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏
- **UUID Primary Keys**: distributed systems ·Ä°·Äê·ÄΩ·ÄÄ·Ä∫ globally unique identifiers
- **Timestamp Tracking**: data changes ·Ä°·Äê·ÄΩ·ÄÄ·Ä∫ audit trail

### 2. Row Level Security Implementation

```sql
-- Enable RLS on multi-tenant tables
ALTER TABLE retail.customers ENABLE ROW LEVEL SECURITY;
ALTER TABLE retail.orders ENABLE ROW LEVEL SECURITY;
ALTER TABLE retail.order_items ENABLE ROW LEVEL SECURITY;

-- Store manager can only see their store's data
CREATE POLICY store_manager_customers ON retail.customers
    FOR ALL TO store_managers
    USING (store_id = get_current_user_store());

CREATE POLICY store_manager_orders ON retail.orders
    FOR ALL TO store_managers
    USING (store_id = get_current_user_store());

-- Regional managers see multiple stores
CREATE POLICY regional_manager_orders ON retail.orders
    FOR ALL TO regional_managers
    USING (store_id = ANY(get_user_store_list()));

-- Support function for RLS context
CREATE OR REPLACE FUNCTION get_current_user_store()
RETURNS UUID AS $$
BEGIN
    RETURN current_setting('app.current_rls_user_id')::UUID;
EXCEPTION WHEN OTHERS THEN
    RETURN '00000000-0000-0000-0000-000000000000'::UUID;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;
```

**RLS ·Ä°·ÄÄ·Äª·Ä≠·ÄØ·Ä∏·ÄÄ·Äª·Ä±·Ä∏·Äá·Ä∞·Ä∏·Äô·Äª·Ä¨·Ä∏**:
- **Automatic Filtering**: database ·ÄÄ data isolation ·ÄÄ·Ä≠·ÄØ ·Ä°·Äú·Ä≠·ÄØ·Ä°·Äú·Äª·Ä±·Ä¨·ÄÄ·Ä∫ enforce ·Äú·ÄØ·Äï·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏
- **Application Simplicity**: WHERE clauses ·Äô·Äú·Ä≠·ÄØ·Ä°·Äï·Ä∫·Ä°·Ä±·Ä¨·ÄÑ·Ä∫ ·Äú·ÄØ·Äï·Ä∫·ÄÜ·Ä±·Ä¨·ÄÑ·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏
- **Security by Default**: data ·Äô·Äæ·Ä¨·Ä∏·Äû·ÄØ·Ä∂·Ä∏·Äô·Ä≠·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏·ÄÄ·Ä≠·ÄØ ·Äô·Äñ·Äº·ÄÖ·Ä∫·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Ä°·Ä±·Ä¨·ÄÑ·Ä∫ ·Äú·ÄØ·Äï·Ä∫·ÄÜ·Ä±·Ä¨·ÄÑ·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏
- **Audit Compliance**: data access boundary ·Äê·ÄΩ·Ä±·ÄÄ·Ä≠·ÄØ ·Äõ·Äæ·ÄÑ·Ä∫·Ä∏·Äú·ÄÑ·Ä∫·Ä∏·ÄÖ·ÄΩ·Ä¨ ·Äñ·Ä±·Ä¨·Ä∫·Äï·Äº·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏

### 3. Vector Search Schema

```sql
-- Product embeddings for semantic search
CREATE TABLE retail.product_description_embeddings (
    product_id UUID PRIMARY KEY REFERENCES retail.products(product_id),
    description_embedding vector(1536),
    last_updated TIMESTAMP DEFAULT NOW()
);

-- Optimize vector similarity search
CREATE INDEX idx_product_embeddings_vector 
ON retail.product_description_embeddings 
USING ivfflat (description_embedding vector_cosine_ops);

-- Semantic search function
CREATE OR REPLACE FUNCTION search_products_by_description(
    query_embedding vector(1536),
    similarity_threshold FLOAT DEFAULT 0.7,
    max_results INTEGER DEFAULT 20
)
RETURNS TABLE(
    product_id UUID,
    name VARCHAR,
    description TEXT,
    similarity_score FLOAT
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        p.product_id,
        p.name,
        p.description,
        (1 - (pde.description_embedding <=> query_embedding)) AS similarity_score
    FROM retail.products p
    JOIN retail.product_description_embeddings pde ON p.product_id = pde.product_id
    WHERE (pde.description_embedding <=> query_embedding) <= (1 - similarity_threshold)
    ORDER BY similarity_score DESC
    LIMIT max_results;
END;
$$ LANGUAGE plpgsql;
```

## üîå Connection Management Patterns

MCP server performance ·Ä°·Äê·ÄΩ·ÄÄ·Ä∫ database connection management ·ÄÄ·Ä≠·ÄØ ·Äë·Ä≠·Äõ·Ä±·Ä¨·ÄÄ·Ä∫·ÄÖ·ÄΩ·Ä¨ ·Äú·ÄØ·Äï·Ä∫·ÄÜ·Ä±·Ä¨·ÄÑ·Ä∫·Äõ·Äï·Ä´·Äô·Äö·Ä∫:

### Connection Pool Configuration

```python
class ConnectionPoolManager:
    """Manages PostgreSQL connection pools."""
    
    async def create_pool(self) -> Pool:
        """Create optimized connection pool."""
        return await asyncpg.create_pool(
            host=self.config.db_host,
            port=self.config.db_port,
            database=self.config.db_name,
            user=self.config.db_user,
            password=self.config.db_password,
            
            # Pool configuration
            min_size=2,          # Minimum connections
            max_size=10,         # Maximum connections
            max_inactive_connection_lifetime=300,  # 5 minutes
            
            # Query configuration
            command_timeout=30,   # Query timeout
            server_settings={
                "application_name": "zava-mcp-server",
                "jit": "off",          # Disable JIT for stability
                "work_mem": "4MB",     # Limit work memory
                "statement_timeout": "30s"
            }
        )
    
    async def execute_with_retry(
        self, 
        query: str, 
        params: Tuple = None,
        max_retries: int = 3
    ) -> List[Dict[str, Any]]:
        """Execute query with automatic retry logic."""
        
        for attempt in range(max_retries):
            try:
                async with self.pool.acquire() as conn:
                    if params:
                        rows = await conn.fetch(query, *params)
                    else:
                        rows = await conn.fetch(query)
                    return [dict(row) for row in rows]
                    
            except (ConnectionError, InterfaceError) as e:
                if attempt == max_retries - 1:
                    raise
                
                # Exponential backoff
                await asyncio.sleep(2 ** attempt)
                logger.warning(f"Database connection failed, retrying ({attempt + 1}/{max_retries})")
```

### Resource Lifecycle Management

```python
class MCPServerManager:
    """Manages MCP server lifecycle and resources."""
    
    async def startup(self):
        """Initialize server resources."""
        # Create database connection pool
        self.db_pool = await self.pool_manager.create_pool()
        
        # Initialize AI services
        self.ai_client = await self.create_ai_client()
        
        # Setup monitoring
        self.metrics_collector = MetricsCollector()
        
        logger.info("MCP server startup complete")
    
    async def shutdown(self):
        """Cleanup server resources."""
        try:
            # Close database connections
            if self.db_pool:
                await self.db_pool.close()
            
            # Cleanup AI client
            if self.ai_client:
                await self.ai_client.close()
            
            # Flush metrics
            await self.metrics_collector.flush()
            
            logger.info("MCP server shutdown complete")
            
        except Exception as e:
            logger.error(f"Error during shutdown: {e}")
    
    async def health_check(self) -> Dict[str, str]:
        """Verify server health status."""
        status = {}
        
        # Check database connection
        try:
            async with self.db_pool.acquire() as conn:
                await conn.fetchval("SELECT 1")
            status["database"] = "healthy"
        except Exception as e:
            status["database"] = f"unhealthy: {e}"
        
        # Check AI service
        try:
            await self.ai_client.health_check()
            status["ai_service"] = "healthy"
        except Exception as e:
            status["ai_service"] = f"unhealthy: {e}"
        
        return status
```

## üõ°Ô∏è Error Handling ·Äî·Ä≤·Ä∑ Resilience Patterns

Error handling ·ÄÄ·Ä≠·ÄØ ·ÄÅ·Ä≠·ÄØ·ÄÑ·Ä∫·ÄÅ·Ä∂·Ä∑·ÄÖ·ÄΩ·Ä¨ ·Äú·ÄØ·Äï·Ä∫·ÄÜ·Ä±·Ä¨·ÄÑ·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏·ÄÄ MCP server operation ·ÄÄ·Ä≠·ÄØ ·Äö·ÄØ·Ä∂·ÄÄ·Äº·Ää·Ä∫·ÄÖ·Ä≠·Äê·Ä∫·ÄÅ·Äª·ÄÖ·ÄΩ·Ä¨ ·Äú·ÄØ·Äï·Ä∫·ÄÜ·Ä±·Ä¨·ÄÑ·Ä∫·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·ÄÖ·Ä±·Äï·Ä´·Äê·Äö·Ä∫:

### Hierarchical Error Types

```python
class MCPError(Exception):
    """Base MCP server error."""
    def __init__(self, message: str, error_code: str = "MCP_ERROR"):
        self.message = message
        self.error_code = error_code
        super().__init__(message)

class DatabaseError(MCPError):
    """Database operation errors."""
    def __init__(self, message: str, query: str = None):
        super().__init__(message, "DATABASE_ERROR")
        self.query = query

class AuthorizationError(MCPError):
    """Access control errors."""
    def __init__(self, message: str, user_id: str = None):
        super().__init__(message, "AUTHORIZATION_ERROR")
        self.user_id = user_id

class QueryTimeoutError(DatabaseError):
    """Query execution timeout."""
    def __init__(self, query: str):
        super().__init__(f"Query timeout: {query[:100]}...", query)
        self.error_code = "QUERY_TIMEOUT"

class ValidationError(MCPError):
    """Input validation errors."""
    def __init__(self, field: str, value: Any, constraint: str):
        message = f"Validation failed for {field}: {constraint}"
        super().__init__(message, "VALIDATION_ERROR")
        self.field = field
        self.value = value
```

### Error Handling Middleware

```python
@contextmanager
async def error_handling_context(operation_name: str, user_id: str = None):
    """Centralized error handling for operations."""
    start_time = time.time()
    
    try:
        yield
        
        # Success metrics
        duration = time.time() - start_time
        metrics.operation_success.labels(operation=operation_name).inc()
        metrics.operation_duration.labels(operation=operation_name).observe(duration)
        
    except ValidationError as e:
        logger.warning(f"Validation error in {operation_name}: {e.message}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "validation",
            "field": e.field
        })
        metrics.operation_error.labels(operation=operation_name, type="validation").inc()
        raise
        
    except AuthorizationError as e:
        logger.warning(f"Authorization error in {operation_name}: {e.message}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "authorization"
        })
        metrics.operation_error.labels(operation=operation_name, type="authorization").inc()
        raise
        
    except DatabaseError as e:
        logger.error(f"Database error in {operation_name}: {e.message}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "database",
            "query": e.query[:100] if e.query else None
        })
        metrics.operation_error.labels(operation=operation_name, type="database").inc()
        raise
        
    except Exception as e:
        logger.error(f"Unexpected error in {operation_name}: {str(e)}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "unexpected"
        }, exc_info=True)
        metrics.operation_error.labels(operation=operation_name, type="unexpected").inc()
        raise MCPError(f"Internal server error in {operation_name}")
```

## üìä Performance Optimization Strategies

### Query Performance Monitoring

```python
class QueryPerformanceMonitor:
    """Monitor and optimize query performance."""
    
    def __init__(self):
        self.slow_query_threshold = 1.0  # seconds
        self.query_stats = defaultdict(list)
    
    @contextmanager
    async def monitor_query(self, query: str, operation_type: str = "unknown"):
        """Monitor query execution time and performance."""
        start_time = time.time()
        query_hash = hashlib.md5(query.encode()).hexdigest()[:8]
        
        try:
            yield
            
            duration = time.time() - start_time
            
            # Record performance metrics
            self.query_stats[operation_type].append(duration)
            
            # Log slow queries
            if duration > self.slow_query_threshold:
                logger.warning(f"Slow query detected", extra={
                    "query_hash": query_hash,
                    "duration": duration,
                    "operation_type": operation_type,
                    "query": query[:200]
                })
            
            # Update metrics
            metrics.query_duration.labels(type=operation_type).observe(duration)
            
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"Query failed", extra={
                "query_hash": query_hash,
                "duration": duration,
                "operation_type": operation_type,
                "error": str(e)
            })
            raise
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """Generate performance summary report."""
        summary = {}
        
        for operation_type, durations in self.query_stats.items():
            if durations:
                summary[operation_type] = {
                    "count": len(durations),
                    "avg_duration": sum(durations) / len(durations),
                    "max_duration": max(durations),
                    "min_duration": min(durations),
                    "slow_queries": len([d for d in durations if d > self.slow_query_threshold])
                }
        
        return summary
```

### Caching Strategy

```python
class QueryCache:
    """Intelligent query result caching."""
    
    def __init__(self, redis_url: str = None):
        self.cache = {}  # In-memory fallback
        self.redis_client = redis.Redis.from_url(redis_url) if redis_url else None
        self.cache_ttl = 300  # 5 minutes default
    
    async def get_cached_result(
        self, 
        cache_key: str, 
        query_func: Callable,
        ttl: int = None
    ) -> Any:
        """Get result from cache or execute query."""
        ttl = ttl or self.cache_ttl
        
        # Try cache first
        cached_result = await self._get_from_cache(cache_key)
        if cached_result is not None:
            metrics.cache_hit.labels(type="query").inc()
            return cached_result
        
        # Execute query
        metrics.cache_miss.labels(type="query").inc()
        result = await query_func()
        
        # Cache result
        await self._set_in_cache(cache_key, result, ttl)
        
        return result
    
    def _generate_cache_key(self, query: str, user_context: str) -> str:
        """Generate consistent cache key."""
        key_data = f"{query}:{user_context}"
        return hashlib.sha256(key_data.encode()).hexdigest()
```

## üéØ ·Ä°·Äì·Ä≠·ÄÄ ·Ä°·ÄÄ·Äª·Ä≠·ÄØ·Ä∏·ÄÄ·Äª·Ä±·Ä∏·Äá·Ä∞·Ä∏·Äô·Äª·Ä¨·Ä∏

·Äí·ÄÆ Lab ·ÄÄ·Ä≠·ÄØ ·Äï·Äº·ÄÆ·Ä∏·ÄÜ·ÄØ·Ä∂·Ä∏·Äê·Ä≤·Ä∑·Ä°·ÄÅ·Ä´·Äô·Äæ·Ä¨ ·Äû·ÄÑ·Ä∫·Äî·Ä¨·Ä∏·Äú·Ää·Ä∫·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Äô·Äö·Ä∑·Ä∫·Ä°·ÄÅ·Äª·ÄÄ·Ä∫·Äê·ÄΩ·Ä±:

‚úÖ **Layered Architecture**: MCP server design ·Äô·Äæ·Ä¨ concern ·Äê·ÄΩ·Ä±·ÄÄ·Ä≠·ÄØ ·ÄÅ·ÄΩ·Ä≤·ÄÅ·Äº·Ä¨·Ä∏·Äë·Ä¨·Ä∏·Äê·Ä≤·Ä∑ ·Äî·Ää·Ä∫·Ä∏·Äú·Äô·Ä∫·Ä∏  
‚úÖ **Database Patterns**: Multi-tenant schema design ·Äî·Ä≤·Ä∑ RLS implementation  
‚úÖ **Connection Management**: pooling ·Äî·Ä≤·Ä∑ resource lifecycle ·ÄÄ·Ä≠·ÄØ ·Äë·Ä≠·Äõ·Ä±·Ä¨·ÄÄ·Ä∫·ÄÖ·ÄΩ·Ä¨ ·Äú·ÄØ·Äï·Ä∫·ÄÜ·Ä±·Ä¨·ÄÑ·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏  
‚úÖ **Error Handling**: Hierarchical error types ·Äî·Ä≤·Ä∑ resilience patterns  
‚úÖ **Performance Optimization**: monitoring, caching, ·Äî·Ä≤·Ä∑ query optimization  
‚úÖ **Production Readiness**: infrastructure concerns ·Äî·Ä≤·Ä∑ operational patterns  

## üöÄ ·Äî·Ä±·Ä¨·ÄÄ·Ä∫·Äê·ÄÖ·Ä∫·ÄÅ·ÄØ

**[Lab 02: Security and Multi-Tenancy](../02-Security/README.md)** ·ÄÄ·Ä≠·ÄØ ·ÄÜ·ÄÄ·Ä∫·Äú·ÄÄ·Ä∫·Äú·Ä±·Ä∑·Äú·Ä¨·Äï·Äº·ÄÆ·Ä∏:

- Row Level Security implementation ·Ä°·ÄÅ·Äª·ÄÄ·Ä∫·Ä°·Äú·ÄÄ·Ä∫·Äô·Äª·Ä¨·Ä∏
- Authentication ·Äî·Ä≤·Ä∑ authorization patterns
- Multi-tenant data isolation ·Äî·Ää·Ä∫·Ä∏·Äú·Äô·Ä∫·Ä∏·Äô·Äª·Ä¨·Ä∏
- Security audit ·Äî·Ä≤·Ä∑ compliance ·Ä°·ÄÅ·Äª·ÄÄ·Ä∫·Ä°·Äú·ÄÄ·Ä∫·Äô·Äª·Ä¨·Ä∏

## üìö ·Ä°·Äï·Ä≠·ÄØ·ÄÜ·Ä±·Ä¨·ÄÑ·Ä∫·Ä∏ ·Äõ·ÄÑ·Ä∫·Ä∏·Äô·Äº·ÄÖ·Ä∫·Äô·Äª·Ä¨·Ä∏

### Architecture Patterns
- [Clean Architecture in Python](https://github.com/cosmic-python/code) - Python applications ·Ä°·Äê·ÄΩ·ÄÄ·Ä∫ architectural patterns
- [Database Design Patterns](https://en.wikipedia.org/wiki/Database_design) - Relational database design ·Ä°·ÄÅ·Äº·Ä±·ÄÅ·Ä∂·Ä°·Äö·Ä∞·Ä°·ÄÜ·Äô·Äª·Ä¨·Ä∏
- [Microservices Patterns](https://microservices.io/patterns/) - Service architecture patterns

### PostgreSQL Advanced Topics
- [PostgreSQL Performance Tuning](https://wiki.postgresql.org/wiki/Performance_Optimization) - Database optimization ·Äú·Äô·Ä∫·Ä∏·Ää·ÄΩ·Äæ·Äî·Ä∫
- [Connection Pooling Best Practices](https://www.postgresql.org/docs/current/runtime-config-connection.html) - Connection management
- [Query Planning and Optimization](https://www.postgresql.org/docs/current/planner-optimizer.html) - Query performance

### Python Async Patterns
- [AsyncIO Best Practices](https://docs.python.org/3/library/asyncio.html) - Async programming patterns
- [FastAPI Architecture](https://fastapi.tiangolo.com/advanced/) - Modern Python web architecture
- [Pydantic Models](https://pydantic-docs.helpmanual.io/) - Data validation ·Äî·Ä≤·Ä∑ serialization

---

**·Äî·Ä±·Ä¨·ÄÄ·Ä∫·Äê·ÄÖ·Ä∫·ÄÅ·ÄØ**: Security patterns ·Äê·ÄΩ·Ä±·ÄÄ·Ä≠·ÄØ ·Äú·Ä±·Ä∑·Äú·Ä¨·Äñ·Ä≠·ÄØ·Ä∑·Ä°·Äê·ÄΩ·ÄÄ·Ä∫ [Lab 02: Security and Multi-Tenancy](../02-Security/README.md) ·ÄÄ·Ä≠·ÄØ ·ÄÜ·ÄÄ·Ä∫·Äú·ÄÄ·Ä∫·Äú·Ä±·Ä∑·Äú·Ä¨·Äï·Ä´!

---

**·Ä°·ÄÄ·Äº·Ä±·Ä¨·ÄÑ·Ä∫·Ä∏·ÄÄ·Äº·Ä¨·Ä∏·ÄÅ·Äª·ÄÄ·Ä∫**:  
·Ä§·ÄÖ·Ä¨·Äõ·ÄΩ·ÄÄ·Ä∫·ÄÖ·Ä¨·Äê·Äô·Ä∫·Ä∏·ÄÄ·Ä≠·ÄØ AI ·Äò·Ä¨·Äû·Ä¨·Äï·Äº·Äî·Ä∫·Äù·Äî·Ä∫·ÄÜ·Ä±·Ä¨·ÄÑ·Ä∫·Äô·Äæ·ÄØ [Co-op Translator](https://github.com/Azure/co-op-translator) ·ÄÄ·Ä≠·ÄØ ·Ä°·Äû·ÄØ·Ä∂·Ä∏·Äï·Äº·ÄØ·Åç ·Äò·Ä¨·Äû·Ä¨·Äï·Äº·Äî·Ä∫·Äë·Ä¨·Ä∏·Äï·Ä´·Äû·Ää·Ä∫·Åã ·ÄÄ·Äª·ÄΩ·Äî·Ä∫·ÄØ·Äï·Ä∫·Äê·Ä≠·ÄØ·Ä∑·Äû·Ää·Ä∫ ·Äê·Ä≠·ÄÄ·Äª·Äô·Äæ·ÄØ·Ä°·Äê·ÄΩ·ÄÄ·Ä∫ ·ÄÄ·Äº·Ä≠·ÄØ·Ä∏·ÄÖ·Ä¨·Ä∏·Äî·Ä±·Äû·Ä±·Ä¨·Ä∫·Äú·Ää·Ä∫·Ä∏ ·Ä°·Äú·Ä≠·ÄØ·Ä°·Äú·Äª·Ä±·Ä¨·ÄÄ·Ä∫ ·Äò·Ä¨·Äû·Ä¨·Äï·Äº·Äî·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏·Äê·ÄΩ·ÄÑ·Ä∫ ·Ä°·Äô·Äæ·Ä¨·Ä∏·Äô·Äª·Ä¨·Ä∏ ·Äû·Ä≠·ÄØ·Ä∑·Äô·Äü·ÄØ·Äê·Ä∫ ·Äô·Äô·Äæ·Äî·Ä∫·ÄÄ·Äî·Ä∫·Äô·Äæ·ÄØ·Äô·Äª·Ä¨·Ä∏ ·Äï·Ä´·Äù·ÄÑ·Ä∫·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Äû·Ää·Ä∫·ÄÄ·Ä≠·ÄØ ·Äû·Äê·Ä≠·Äï·Äº·ÄØ·Äï·Ä´·Åã ·Äô·Ä∞·Äõ·ÄÑ·Ä∫·Ä∏·ÄÖ·Ä¨·Äõ·ÄΩ·ÄÄ·Ä∫·ÄÖ·Ä¨·Äê·Äô·Ä∫·Ä∏·ÄÄ·Ä≠·ÄØ ·Åé·ÄÑ·Ä∫·Ä∏·Åè ·Äô·Ä∞·Äú·Äò·Ä¨·Äû·Ä¨·ÄÖ·ÄÄ·Ä¨·Ä∏·Äñ·Äº·ÄÑ·Ä∑·Ä∫ ·Ä°·Ä¨·Äè·Ä¨·Äê·Äõ·Ä¨·Ä∏·Äõ·Äæ·Ä≠·Äû·Ä±·Ä¨·Ä°·Äõ·ÄÑ·Ä∫·Ä∏·Ä°·Äô·Äº·ÄÖ·Ä∫·Ä°·Äñ·Äº·ÄÖ·Ä∫ ·Äû·Äê·Ä∫·Äô·Äæ·Äê·Ä∫·Äû·ÄÑ·Ä∑·Ä∫·Äï·Ä´·Äû·Ää·Ä∫·Åã ·Ä°·Äõ·Ä±·Ä∏·ÄÄ·Äº·ÄÆ·Ä∏·Äû·Ä±·Ä¨ ·Ä°·ÄÅ·Äª·ÄÄ·Ä∫·Ä°·Äú·ÄÄ·Ä∫·Äô·Äª·Ä¨·Ä∏·Ä°·Äê·ÄΩ·ÄÄ·Ä∫ ·Äú·Ä∞·Ä∑·Äò·Ä¨·Äû·Ä¨·Äï·Äº·Äî·Ä∫·Äï·Ää·Ä¨·Äõ·Äæ·ÄÑ·Ä∫·Äô·Äª·Ä¨·Ä∏·Äô·Äæ ·Äï·Äõ·Ä±·Ä¨·Ä∫·Äñ·ÄÄ·Ä∫·Äõ·Äæ·ÄÑ·Ä∫·Äî·Äö·Ä∫ ·Äò·Ä¨·Äû·Ä¨·Äï·Äº·Äî·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏·ÄÄ·Ä≠·ÄØ ·Ä°·ÄÄ·Äº·Ä∂·Äï·Äº·ÄØ·Äï·Ä´·Äû·Ää·Ä∫·Åã ·Ä§·Äò·Ä¨·Äû·Ä¨·Äï·Äº·Äî·Ä∫·ÄÄ·Ä≠·ÄØ ·Ä°·Äû·ÄØ·Ä∂·Ä∏·Äï·Äº·ÄØ·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏·Äô·Äæ ·Äñ·Äº·ÄÖ·Ä∫·Äï·Ä±·Ä´·Ä∫·Äú·Ä¨·Äû·Ä±·Ä¨ ·Ä°·Äú·ÄΩ·Ä≤·Ä°·Äô·Äæ·Ä¨·Ä∏·Äô·Äª·Ä¨·Ä∏ ·Äû·Ä≠·ÄØ·Ä∑·Äô·Äü·ÄØ·Äê·Ä∫ ·Ä°·Äî·Ä¨·Ä∏·Äú·ÄΩ·Ä≤·Äô·Äæ·ÄØ·Äô·Äª·Ä¨·Ä∏·Ä°·Äï·Ä±·Ä´·Ä∫ ·ÄÄ·Äª·ÄΩ·Äî·Ä∫·ÄØ·Äï·Ä∫·Äê·Ä≠·ÄØ·Ä∑·Äû·Ää·Ä∫ ·Äê·Ä¨·Äù·Äî·Ä∫·Äô·Äö·Ä∞·Äï·Ä´·Åã