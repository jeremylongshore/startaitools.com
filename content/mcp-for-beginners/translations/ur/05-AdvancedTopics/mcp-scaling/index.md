<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7b4d8d17fc1f501468cce40c3651aed1",
  "translation_date": "2025-07-16T23:48:58+00:00",
  "source_file": "05-AdvancedTopics/mcp-scaling/README.md",
  "language_code": "ur"
}
-->
# Scalability and High-Performance MCP

انٹرپرائز تعیناتیوں کے لیے، MCP کی تنصیبات کو اکثر کم سے کم تاخیر کے ساتھ بڑی تعداد میں درخواستوں کو سنبھالنا ہوتا ہے۔

## تعارف

اس سبق میں، ہم MCP سرورز کو بڑے کام کے بوجھ کو مؤثر طریقے سے سنبھالنے کے لیے اسکیل کرنے کی حکمت عملیوں کا جائزہ لیں گے۔ ہم افقی اور عمودی اسکیلنگ، وسائل کی بہتر کاری، اور تقسیم شدہ معماریات پر بات کریں گے۔

## سیکھنے کے مقاصد

اس سبق کے اختتام تک، آپ قابل ہوں گے:

- لوڈ بیلنسنگ اور تقسیم شدہ کیشنگ کے ذریعے افقی اسکیلنگ کو نافذ کریں۔
- عمودی اسکیلنگ اور وسائل کے انتظام کے لیے MCP سرورز کو بہتر بنائیں۔
- اعلی دستیابی اور خرابی برداشت کے لیے تقسیم شدہ MCP معماریات ڈیزائن کریں۔
- کارکردگی کی نگرانی اور بہتر کاری کے لیے جدید آلات اور تکنیکوں کا استعمال کریں۔
- پروڈکشن ماحول میں MCP سرورز کی اسکیلنگ کے بہترین طریقے اپنائیں۔

## اسکیل ایبلٹی کی حکمت عملیاں

MCP سرورز کو مؤثر طریقے سے اسکیل کرنے کے لیے کئی حکمت عملیاں موجود ہیں:

- **افقی اسکیلنگ**: لوڈ بیلینسر کے پیچھے متعدد MCP سرورز کی مثالیں تعینات کریں تاکہ آنے والی درخواستوں کو برابر تقسیم کیا جا سکے۔
- **عمودی اسکیلنگ**: ایک واحد MCP سرور کی مثال کو زیادہ درخواستیں سنبھالنے کے لیے وسائل (CPU، میموری) بڑھا کر اور کنفیگریشنز کو بہتر بنا کر بہتر کریں۔
- **وسائل کی بہتر کاری**: مؤثر الگورتھمز، کیشنگ، اور غیر ہم وقت ساز پروسیسنگ کا استعمال کر کے وسائل کی کھپت کم کریں اور جواب دینے کے اوقات کو بہتر بنائیں۔
- **تقسیم شدہ معماریہ**: ایک ایسا تقسیم شدہ نظام نافذ کریں جہاں متعدد MCP نوڈز مل کر کام کریں، بوجھ کو بانٹیں اور اضافی تحفظ فراہم کریں۔

## افقی اسکیلنگ

افقی اسکیلنگ میں متعدد MCP سرورز کی مثالیں تعینات کرنا اور لوڈ بیلینسر کے ذریعے آنے والی درخواستوں کو تقسیم کرنا شامل ہے۔ یہ طریقہ آپ کو بیک وقت زیادہ درخواستیں سنبھالنے اور خرابی برداشت کرنے کی سہولت دیتا ہے۔

آئیے دیکھتے ہیں کہ افقی اسکیلنگ اور MCP کو کیسے ترتیب دیا جائے۔

### [.NET](../../../../05-AdvancedTopics/mcp-scaling)

```csharp
// ASP.NET Core MCP load balancing configuration
public class McpLoadBalancedStartup
{
    public void ConfigureServices(IServiceCollection services)
    {
        // Configure distributed cache for session state
        services.AddStackExchangeRedisCache(options =>
        {
            options.Configuration = Configuration.GetConnectionString("RedisConnection");
            options.InstanceName = "MCP_";
        });
        
        // Configure MCP with distributed caching
        services.AddMcpServer(options =>
        {
            options.ServerName = "Scalable MCP Server";
            options.ServerVersion = "1.0.0";
            options.EnableDistributedCaching = true;
            options.CacheExpirationMinutes = 60;
        });
        
        // Register tools
        services.AddMcpTool<HighPerformanceTool>();
    }
}
```

پچھلے کوڈ میں ہم نے:

- Redis کا استعمال کرتے ہوئے سیشن اسٹیٹ اور ٹول ڈیٹا ذخیرہ کرنے کے لیے تقسیم شدہ کیش ترتیب دی۔
- MCP سرور کی کنفیگریشن میں تقسیم شدہ کیشنگ کو فعال کیا۔
- ایک ہائی پرفارمنس ٹول رجسٹر کیا جو متعدد MCP مثالوں میں استعمال ہو سکتا ہے۔

---

## عمودی اسکیلنگ اور وسائل کی بہتر کاری

عمودی اسکیلنگ کا مقصد ایک واحد MCP سرور کی مثال کو زیادہ درخواستیں مؤثر طریقے سے سنبھالنے کے لیے بہتر بنانا ہے۔ یہ کنفیگریشنز کو بہتر بنا کر، مؤثر الگورتھمز استعمال کر کے، اور وسائل کا مؤثر انتظام کر کے حاصل کیا جا سکتا ہے۔ مثال کے طور پر، آپ تھریڈ پولز، درخواست کے ٹائم آؤٹ، اور میموری کی حدوں کو ایڈجسٹ کر کے کارکردگی بہتر بنا سکتے ہیں۔

آئیے دیکھتے ہیں کہ MCP سرور کو عمودی اسکیلنگ اور وسائل کے انتظام کے لیے کیسے بہتر بنایا جائے۔

# [Java](../../../../05-AdvancedTopics/mcp-scaling)

```java
// Java MCP server with resource optimization
public class OptimizedMcpServer {
    public static McpServer createOptimizedServer() {
        // Configure thread pool for optimal performance
        int processors = Runtime.getRuntime().availableProcessors();
        int optimalThreads = processors * 2; // Common heuristic for I/O-bound tasks
        
        ExecutorService executorService = new ThreadPoolExecutor(
            processors,       // Core pool size
            optimalThreads,   // Maximum pool size 
            60L,              // Keep-alive time
            TimeUnit.SECONDS,
            new ArrayBlockingQueue<>(1000), // Request queue size
            new ThreadPoolExecutor.CallerRunsPolicy() // Backpressure strategy
        );
        
        // Configure and build MCP server with resource constraints
        return new McpServer.Builder()
            .setName("High-Performance MCP Server")
            .setVersion("1.0.0")
            .setPort(5000)
            .setExecutor(executorService)
            .setMaxRequestSize(1024 * 1024) // 1MB
            .setMaxConcurrentRequests(100)
            .setRequestTimeoutMs(5000) // 5 seconds
            .build();
    }
}
```

پچھلے کوڈ میں ہم نے:

- دستیاب پروسیسرز کی تعداد کی بنیاد پر تھریڈز کی ایک مثالی تعداد کے ساتھ تھریڈ پول ترتیب دیا۔
- وسائل کی حدود جیسے زیادہ سے زیادہ درخواست کا سائز، زیادہ سے زیادہ متوازی درخواستیں، اور درخواست کا ٹائم آؤٹ مقرر کیا۔
- بیک پریشر حکمت عملی استعمال کی تاکہ زیادہ بوجھ کی صورت میں حالات کو ہمواری سے سنبھالا جا سکے۔

---

## تقسیم شدہ معماریہ

تقسیم شدہ معماریات میں متعدد MCP نوڈز مل کر کام کرتے ہیں تاکہ درخواستوں کو سنبھالیں، وسائل کا اشتراک کریں، اور اضافی تحفظ فراہم کریں۔ یہ طریقہ اسکیل ایبلٹی اور خرابی برداشت کو بہتر بناتا ہے کیونکہ نوڈز ایک دوسرے سے بات چیت اور ہم آہنگی کے ذریعے کام کرتے ہیں۔

آئیے دیکھتے ہیں کہ Redis کے ذریعے ہم آہنگی کے لیے تقسیم شدہ MCP سرور معماریہ کیسے نافذ کی جائے۔

# [Python](../../../../05-AdvancedTopics/mcp-scaling)

```python
# Python MCP server in distributed architecture
from mcp_server import AsyncMcpServer
import asyncio
import aioredis
import uuid

class DistributedMcpServer:
    def __init__(self, node_id=None):
        self.node_id = node_id or str(uuid.uuid4())
        self.redis = None
        self.server = None
    
    async def initialize(self):
        # Connect to Redis for coordination
        self.redis = await aioredis.create_redis_pool("redis://redis-master:6379")
        
        # Register this node with the cluster
        await self.redis.sadd("mcp:nodes", self.node_id)
        await self.redis.hset(f"mcp:node:{self.node_id}", "status", "starting")
        
        # Create the MCP server
        self.server = AsyncMcpServer(
            name=f"MCP Node {self.node_id[:8]}",
            version="1.0.0",
            port=5000,
            max_concurrent_requests=50
        )
        
        # Register tools - each node might specialize in certain tools
        self.register_tools()
        
        # Start heartbeat mechanism
        asyncio.create_task(self._heartbeat())
        
        # Start server
        await self.server.start()
        
        # Update node status
        await self.redis.hset(f"mcp:node:{self.node_id}", "status", "running")
        print(f"MCP Node {self.node_id[:8]} running on port 5000")
    
    def register_tools(self):
        # Register common tools across all nodes
        self.server.register_tool(CommonTool1())
        self.server.register_tool(CommonTool2())
        
        # Register specialized tools for this node (could be based on node_id or config)
        if int(self.node_id[-1], 16) % 3 == 0:  # Simple way to distribute specialized tools
            self.server.register_tool(SpecializedTool1())
        elif int(self.node_id[-1], 16) % 3 == 1:
            self.server.register_tool(SpecializedTool2())
        else:
            self.server.register_tool(SpecializedTool3())
    
    async def _heartbeat(self):
        """Periodic heartbeat to indicate node health"""
        while True:
            try:
                await self.redis.hset(
                    f"mcp:node:{self.node_id}", 
                    mapping={
                        "lastHeartbeat": int(time.time()),
                        "load": len(self.server.active_requests),
                        "maxLoad": self.server.max_concurrent_requests
                    }
                )
                await asyncio.sleep(5)  # Heartbeat every 5 seconds
            except Exception as e:
                print(f"Heartbeat error: {e}")
                await asyncio.sleep(1)
    
    async def shutdown(self):
        await self.redis.hset(f"mcp:node:{self.node_id}", "status", "stopping")
        await self.server.stop()
        await self.redis.srem("mcp:nodes", self.node_id)
        await self.redis.delete(f"mcp:node:{self.node_id}")
        self.redis.close()
        await self.redis.wait_closed()
```

پچھلے کوڈ میں ہم نے:

- ایک تقسیم شدہ MCP سرور بنایا جو ہم آہنگی کے لیے Redis انسٹینس کے ساتھ رجسٹر ہوتا ہے۔
- نوڈ کی حالت اور بوجھ کو Redis میں اپ ڈیٹ کرنے کے لیے ہارٹ بیٹ میکانزم نافذ کیا۔
- ایسے ٹولز رجسٹر کیے جو نوڈ کی شناخت کی بنیاد پر مخصوص ہو سکتے ہیں، جس سے نوڈز کے درمیان بوجھ کی تقسیم ممکن ہوتی ہے۔
- وسائل کی صفائی اور کلسٹر سے نوڈ کی رجسٹریشن ختم کرنے کے لیے شٹ ڈاؤن طریقہ فراہم کیا۔
- درخواستوں کو مؤثر طریقے سے سنبھالنے اور ردعمل کو برقرار رکھنے کے لیے غیر ہم وقت ساز پروگرامنگ کا استعمال کیا۔
- تقسیم شدہ نوڈز کے درمیان ہم آہنگی اور اسٹیٹ مینجمنٹ کے لیے Redis کا استعمال کیا۔

---

## آگے کیا ہے

- [5.8 Security](../mcp-security/README.md)

**دستخطی نوٹ**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کے ذریعے ترجمہ کی گئی ہے۔ اگرچہ ہم درستگی کے لیے کوشاں ہیں، براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا عدم درستیاں ہو سکتی ہیں۔ اصل دستاویز اپنی مادری زبان میں ہی معتبر ماخذ سمجھی جانی چاہیے۔ اہم معلومات کے لیے پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کی ذمہ داری ہم پر عائد نہیں ہوتی۔